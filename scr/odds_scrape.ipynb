{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
    "chrome_options.add_argument(\"--headless\") \n",
    "\n",
    "# Set up the Chrome WebDriver\n",
    "service = Service(\"/opt/homebrew/bin/chromedriver\")\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Navigate to the specific oddschecker page\n",
    "url = \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/winner\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(10)\n",
    "\n",
    "# Get the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find the table or relevant parts\n",
    "odds_table = soup.find('tbody', id='t1')\n",
    "\n",
    "# Extract each row and the data within\n",
    "odds_data = []\n",
    "bookmakers_set = set()\n",
    "\n",
    "for row in odds_table.find_all('tr'):\n",
    "    market_name = row.find('a', class_='popup').text.strip()  # Extract the party name\n",
    "    odds_dict = {'Market': market_name}\n",
    "    \n",
    "    # Find all td elements with odds information\n",
    "    for td in row.find_all('td', class_=lambda x: x and ('o' in x.split() or 'bs' in x.split())):\n",
    "        bookmaker = td.get('data-bk')  # Extract the bookmaker name\n",
    "        decimal_odds = td.get('data-odig')  # Extract the decimal odds value\n",
    "        if bookmaker and decimal_odds:  # Only add if both are present\n",
    "            odds_dict[bookmaker] = float(decimal_odds)  # Convert odds to float\n",
    "            bookmakers_set.add(bookmaker)\n",
    "    \n",
    "    odds_data.append(odds_dict)\n",
    "\n",
    "# Create a DataFrame with all bookmakers as columns\n",
    "df = pd.DataFrame(odds_data).set_index('Market')\n",
    "\n",
    "# Ensure all bookmakers are columns, even if some are missing in certain rows\n",
    "df = df.reindex(columns=sorted(bookmakers_set))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract oddschecker politics market urls from sitemap\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
    "\n",
    "# Set up the Chrome WebDriver (update the path to where you have your ChromeDriver)\n",
    "service = Service(\"/opt/homebrew/bin/chromedriver\")  # Update this path\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# URL of the sitemap\n",
    "sitemap_url = \"https://www.oddschecker.com/sport/politics/sitemap.xml\"\n",
    "\n",
    "try:\n",
    "    # Load the sitemap page\n",
    "    driver.get(sitemap_url)\n",
    "    \n",
    "    # Wait for the page to fully load (adjust time as needed)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Get the page source (XML content)\n",
    "    xml_content = driver.page_source\n",
    "\n",
    "    # Parse the XML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(xml_content, 'xml')\n",
    "\n",
    "    # Find all <loc> tags which contain the URLs\n",
    "    url_tags = soup.find_all('loc')\n",
    "\n",
    "    # Extract URLs and add them to the list\n",
    "    urls = [url_tag.text for url_tag in url_tags]\n",
    "\n",
    "    print(f\"Found {len(urls)} URLs.\")\n",
    "    print(urls)  # Print the URLs or add further processing\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to extract odds data from a given URL\n",
    "def extract_odds(url, user_agent):\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "    # Set up the Chrome WebDriver\n",
    "    service = Service(\"/opt/homebrew/bin/chromedriver\")\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        # Navigate to the specific oddschecker page\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        time.sleep(10)  # Adjust if necessary\n",
    "\n",
    "        # Get the page source\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Find the table or relevant parts\n",
    "        odds_table = soup.find('tbody', id='t1')\n",
    "\n",
    "        if not odds_table:\n",
    "            print(f\"No odds table found for URL: {url}\")\n",
    "            return None  # Skip this URL if the table isn't found\n",
    "\n",
    "        # Extract each row and the data within\n",
    "        odds_data = []\n",
    "        bookmakers_set = set()\n",
    "\n",
    "        for row in odds_table.find_all('tr'):\n",
    "            party_name = row.find('a', class_='popup').text.strip()  # Extract the party name\n",
    "            odds_dict = {'Party': party_name}\n",
    "            \n",
    "            # Find all td elements with odds information\n",
    "            for td in row.find_all('td', class_=lambda x: x and ('o' in x.split() or 'bs' in x.split())):\n",
    "                bookmaker = td.get('data-bk')  # Extract the bookmaker name\n",
    "                decimal_odds = td.get('data-odig')  # Extract the decimal odds value\n",
    "                if bookmaker and decimal_odds:  # Only add if both are present\n",
    "                    odds_dict[bookmaker] = float(decimal_odds)  # Convert odds to float\n",
    "                    bookmakers_set.add(bookmaker)\n",
    "            \n",
    "            odds_data.append(odds_dict)\n",
    "\n",
    "        # Create a DataFrame with all bookmakers as columns\n",
    "        df = pd.DataFrame(odds_data).set_index('Party')\n",
    "\n",
    "        # Ensure all bookmakers are columns, even if some are missing in certain rows\n",
    "        df = df.reindex(columns=sorted(bookmakers_set))\n",
    "\n",
    "        # Add the URL as a column in the DataFrame\n",
    "        df['URL'] = url\n",
    "\n",
    "        return df\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/winner\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/arizona\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/georgia\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/michigan\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/pennsylvania\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/wisconsin\"\n",
    "]\n",
    "\n",
    "# List of user agents to rotate\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "]\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes_list = []\n",
    "\n",
    "# Use ThreadPoolExecutor to process URLs in parallel in batches of 5\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for i, url in enumerate(urls):\n",
    "        user_agent = user_agents[i % len(user_agents)]  # Rotate user agents\n",
    "        futures.append(executor.submit(extract_odds, url, user_agent))\n",
    "\n",
    "        # Wait for each batch of 5 to complete before starting the next batch\n",
    "        if (i + 1) % 5 == 0 or i == len(urls) - 1:\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                df = future.result()\n",
    "                if df is not None:\n",
    "                    dataframes_list.append(df)\n",
    "            futures = []  # Clear futures list for the next batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import queue\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "bf_usr = os.getenv(\"BF_LOGIN\")\n",
    "bf_pass = os.getenv(\"BF_PASS\")\n",
    "bf_api = os.getenv(\"BF_API_KEY\")\n",
    "#bf_session = os.getenv(\"BF_SESSION\")\n",
    "bf_certs_path = '../certs/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Labour Leader 1.170273835\n",
      "Next Lib Dem Leader 1.179233218\n",
      "Year Rishi Sunak replaced as Conservative Leader 1.205534173\n",
      "Next Conservative Leader 1.205526560\n",
      "Northern Territory Election 2024 1.223219482\n",
      "Queensland State Election 2024 1.218937278\n",
      "Will Joe Biden be impeached before 2024 Election? 1.218257169\n",
      "Senate Control after 2024 Election 1.225479090\n",
      "Election Winner 1.176878927\n",
      "Winning Party 1.178176964\n",
      "Popular Vote Winner 1.178165812\n",
      "Party of Popular Vote Winner 1.178176967\n",
      "Gender of Election Winner 1.178176193\n",
      "Will Election Winner lose Popular Vote? 1.226054697\n",
      "Joe Manchin to be re-elected to the senate in 2024 1.213966025\n",
      "Mississippi 1.230000329\n",
      "Arizona 1.229996509\n",
      "Massachusetts 1.230000327\n",
      "Oklahoma 1.230123427\n",
      "Pennsylvania 1.230123429\n",
      "South Dakota 1.230123632\n",
      "Michigan 1.229999165\n",
      "Oregon 1.230123428\n",
      "Tennessee 1.230123636\n",
      "Minnesota 1.229999638\n",
      "Hawaii 1.229997182\n",
      "Alabama 1.229996495\n",
      "South Carolina 1.230123511\n",
      "Georgia 1.229997102\n",
      "Louisiana 1.229997511\n",
      "Alaska 1.229975960\n",
      "Kentucky 1.229997509\n",
      "Kansas 1.229997508\n",
      "Texas 1.230123858\n",
      "Iowa 1.229997507\n",
      "Maryland 1.230000097\n",
      "Rhode Island 1.230123454\n",
      "New Mexico 1.230123388\n",
      "New Jersey 1.230000502\n",
      "Indiana 1.229997224\n",
      "New Hampshire 1.230000498\n",
      "North Carolina 1.230123393\n",
      "Illinois 1.229997223\n",
      "New York 1.230123391\n",
      "Idaho 1.229997222\n",
      "North Dakota 1.230123395\n",
      "Florida 1.229997015\n",
      "Ohio 1.230123396\n",
      "Delaware 1.229997012\n",
      "Connecticut 1.229997011\n",
      "Colorado 1.229997010\n",
      "California 1.229997007\n",
      "Utah 1.230123883\n",
      "Arkansas 1.229997003\n",
      "Nebraska (Statewide result) 1.230000342\n",
      "Virginia 1.230123893\n",
      "Vermont 1.230123892\n",
      "Nevada 1.230000473\n",
      "West Virginia 1.230123895\n",
      "Washington 1.230123894\n",
      "Montana 1.230000335\n",
      "Wisconsin 1.230123898\n",
      "Missouri 1.230000332\n",
      "Maine (Statewide result) 1.229997534\n",
      "Wyoming 1.230123899\n",
      "Month Rishi Sunak replaced as Conservative Leader 1.223963569\n",
      "Year of Next Scottish Ind Referendum (rule update) 1.166577732\n",
      "Result of ECHR/HRA referendum 1.205300837\n",
      "Year of ECHR/HRA Referendum 1.205300394\n",
      "Most Seats 1.219627935\n",
      "WA State Election 2025 1.232011836\n",
      "Next Federal Election 1.199816099\n",
      "Year of Next Federal Election 1.223219344\n",
      "Conservative Party leader at Next General Election 1.230433061\n",
      "Prime Minister after Keir Starmer 1.230434795\n",
      "Most Seats 1.230583324\n"
     ]
    }
   ],
   "source": [
    "import betfairlightweight\n",
    "from betfairlightweight import filters\n",
    "from betfairlightweight import APIClient\n",
    "\n",
    "client = APIClient(bf_usr, bf_pass, app_key=bf_api, certs=bf_certs_path)\n",
    "#client.session_token = bf_session\n",
    "client.login()\n",
    "\n",
    "market_filter = betfairlightweight.filters.market_filter(\n",
    "    event_type_ids=['2378961'],  # Politics event type\n",
    ")\n",
    "\n",
    "market_catalogues = client.betting.list_market_catalogue(\n",
    "    filter=market_filter,\n",
    "    max_results=100\n",
    ")\n",
    "\n",
    "# Process the market catalogues\n",
    "for market in market_catalogues:\n",
    "    print(market.market_name, market.market_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# create queue\n",
    "output_queue = queue.Queue()\n",
    "\n",
    "# create stream listener\n",
    "listener = betfairlightweight.StreamListener(output_queue=output_queue)\n",
    "\n",
    "# create stream\n",
    "stream = client.streaming.create_stream(listener=listener)\n",
    "\n",
    "# create filters (GB WIN racing)\n",
    "market_filter = filters.streaming_market_filter(\n",
    "    event_type_ids=['2378961']\n",
    ")\n",
    "market_data_filter = filters.streaming_market_data_filter(\n",
    "    fields=[\"EX_BEST_OFFERS\", \"EX_MARKET_DEF\"], ladder_levels=3\n",
    ")\n",
    "\n",
    "# subscribe\n",
    "streaming_unique_id = stream.subscribe_to_markets(\n",
    "    market_filter=market_filter,\n",
    "    market_data_filter=market_data_filter,\n",
    "    conflate_ms=5000,  # send update every 1000ms\n",
    ")\n",
    "\n",
    "# start stream in a new thread (in production would need err handling)\n",
    "t = threading.Thread(target=stream.start, daemon=True)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_runner_books(runner_books):\n",
    "    '''\n",
    "    This function processes the runner books and returns a DataFrame with the best back/lay prices + vol for each runner\n",
    "    :param runner_books:\n",
    "    :return:\n",
    "    '''\n",
    "    best_back_prices = [runner_book.ex.available_to_back[0]['price']\n",
    "        if runner_book.ex.available_to_back\n",
    "        else 1.01\n",
    "        for runner_book\n",
    "        in runner_books]\n",
    "    best_back_sizes = [runner_book.ex.available_to_back[0]['size']\n",
    "        if runner_book.ex.available_to_back\n",
    "        else 1.01\n",
    "        for runner_book\n",
    "        in runner_books]\n",
    "\n",
    "    best_lay_prices = [runner_book.ex.available_to_lay[0]['price']\n",
    "        if runner_book.ex.available_to_lay\n",
    "        else 1000.0\n",
    "        for runner_book\n",
    "        in runner_books]\n",
    "    best_lay_sizes = [runner_book.ex.available_to_lay[0]['size']\n",
    "        if runner_book.ex.available_to_lay\n",
    "        else 1.01\n",
    "        for runner_book\n",
    "        in runner_books]\n",
    "\n",
    "    selection_ids = [runner_book.selection_id for runner_book in runner_books]\n",
    "    last_prices_traded = [runner_book.last_price_traded for runner_book in runner_books]\n",
    "    total_matched = [runner_book.total_matched for runner_book in runner_books]\n",
    "    statuses = [runner_book.status for runner_book in runner_books]\n",
    "    scratching_datetimes = [runner_book.removal_date for runner_book in runner_books]\n",
    "    adjustment_factors = [runner_book.adjustment_factor for runner_book in runner_books]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Selection ID': selection_ids,\n",
    "        'Best Back Price': best_back_prices,\n",
    "        'Best Back Size': best_back_sizes,\n",
    "        'Best Lay Price': best_lay_prices,\n",
    "        'Best Lay Size': best_lay_sizes,\n",
    "        'Last Price Traded': last_prices_traded,\n",
    "        'Total Matched': total_matched,\n",
    "        'Status': statuses,\n",
    "        'Removal Date': scratching_datetimes,\n",
    "        'Adjustment Factor': adjustment_factors\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Create a price filter. Get all traded and offer data\n",
    "price_filter = betfairlightweight.filters.price_projection(\n",
    "    price_data=['EX_BEST_OFFERS']\n",
    ")\n",
    "\n",
    "# Request market books\n",
    "market_books = client.betting.list_market_book(\n",
    "    market_ids=['1.176878927'],\n",
    "    price_projection=price_filter\n",
    ")\n",
    "\n",
    "# Grab the first market book from the returned list as we only requested one market \n",
    "market_book = market_books[0]\n",
    "\n",
    "runners_df = process_runner_books(market_book.runners)\n",
    "\n",
    "runners_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
