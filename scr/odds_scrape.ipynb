{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import concurrent.futures\n",
    "from selenium import webdriver\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import queue\n",
    "import threading\n",
    "\n",
    "import betfairlightweight\n",
    "from betfairlightweight import filters\n",
    "from betfairlightweight import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oddschecker data\n",
    "First extract the urls containing each of the odds tables from the oddschecker politics sitemap at https://www.oddschecker.com/sport/politics/sitemap.xml. However this does appear to be missing a bunch of markets for some reason, so it's simpler to manually update the list of markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 URLs.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Extract oddschecker politics market urls from sitemap\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\") \n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
    "\n",
    "service = Service(\"/opt/homebrew/bin/chromedriver\")\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# URL of the sitemap\n",
    "sitemap_url = \"https://www.oddschecker.com/sport/politics/sitemap.xml\"\n",
    "\n",
    "try:\n",
    "    # Load the sitemap page\n",
    "    driver.get(sitemap_url)\n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    xml_content = driver.page_source\n",
    "    soup = BeautifulSoup(xml_content, 'xml')\n",
    "\n",
    "    url_tags = soup.find_all('loc')\n",
    "    urls = [url_tag.text for url_tag in url_tags]\n",
    "\n",
    "    print(f\"Found {len(urls)} URLs.\")\n",
    "    print(urls)\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium is then used to load the pages and grab the page source. It's currently set to run five pages concurrently (using different headers) to help speed things up. The odds table is then extracted using beautifulsoup, putting the bet name and odds for each bookmaker into a dataframe. The data for the odds of each bookmaker seems to have a somewhat random class name in the html, but most contain \"bs\" or \"o\", so this is what's searched for in the table info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract odds data from a given URL\n",
    "def extract_odds(url, user_agent):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "    service = Service(\"/opt/homebrew/bin/chromedriver\")\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        # Navigate to the specific oddschecker page\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        time.sleep(6) \n",
    "\n",
    "        # Get the page source\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Odds table has id \"t1\"\n",
    "        odds_table = soup.find('tbody', id='t1')\n",
    "\n",
    "        if not odds_table:\n",
    "            print(f\"No odds table found for URL: {url}\")\n",
    "            return None  # Skip this URL if the table isn't found\n",
    "\n",
    "        # Extract each row and the data within\n",
    "        odds_data = []\n",
    "        bookmakers_set = set()\n",
    "\n",
    "        for row in odds_table.find_all('tr'):\n",
    "            bet_name = row.find('a', class_='popup').text.strip() \n",
    "            odds_dict = {'Bet': bet_name}\n",
    "            \n",
    "            # Find all td elements with odds information\n",
    "            for td in row.find_all('td', class_=lambda x: x and ('o' in x.split() or 'bs' in x.split())): \n",
    "                bookmaker = td.get('data-bk')  # Extract the bookmaker name\n",
    "                decimal_odds = td.get('data-odig')  # Extract the decimal odds value\n",
    "                if bookmaker and decimal_odds:  # Only add if both are present\n",
    "                    odds_dict[bookmaker] = float(decimal_odds)  # Convert odds to float\n",
    "                    bookmakers_set.add(bookmaker)\n",
    "            \n",
    "            odds_data.append(odds_dict)\n",
    "\n",
    "        # Create a DataFrame with all bookmakers as columns\n",
    "        df = pd.DataFrame(odds_data).set_index('Bet')\n",
    "\n",
    "        # Ensure all bookmakers are columns, even if some are missing in certain rows\n",
    "        df = df.reindex(columns=sorted(bookmakers_set))\n",
    "\n",
    "        # Add the URL as a column in the DataFrame\n",
    "        df['URL'] = url\n",
    "\n",
    "        return df\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The oddschecker sitemap seems to be missing some pages, so manually updated urls\n",
    "urls = [\n",
    "    \"https://www.oddschecker.com/politics/british-politics/next-labour-leader\",\n",
    "    \"https://www.oddschecker.com/politics/british-politics/next-conservative-leader\",\n",
    "    \"https://www.oddschecker.com/politics/australian-politics/state-elections/queensland-state-election\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/winner\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/winning-party\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/party-of-popular-vote-winner\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/gender-of-election-winner\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/election-winner-to-lose-popular-vote\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/mississippi\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/arizona\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/massachusetts\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/oklahoma\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/pennsylvania\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/oregon\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/minnesota\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/hawaii\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/alabama\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/texas\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/rhode-island\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/florida\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/delaware\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/connecticut\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/colorado\"\n",
    "]\n",
    "\n",
    "# List of user agents to rotate\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "]\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes_list_oc = []\n",
    "\n",
    "# Use ThreadPoolExecutor to process URLs in parallel in batches of 5\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for i, url in enumerate(urls):\n",
    "        user_agent = user_agents[i % len(user_agents)]  # Rotate user agents\n",
    "        futures.append(executor.submit(extract_odds, url, user_agent))\n",
    "\n",
    "        # Wait for each batch of 5 to complete before starting the next batch\n",
    "        if (i + 1) % 5 == 0 or i == len(urls) - 1:\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                df = future.result()\n",
    "                if df is not None:\n",
    "                    dataframes_list_oc.append(df)\n",
    "            futures = []  # Clear futures list for the next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Bet   AKB      B3      BF     BY      CE      DP     EE  \\\n",
      "0      Republicans  0.00    1.57    1.67   0.00    1.61    1.60   1.62   \n",
      "1         Democrat  0.00    2.38    2.43   0.00    2.30    2.40   2.38   \n",
      "2      Independent  0.00  131.00  147.00   0.00  101.00  101.00  51.00   \n",
      "3     Donald Trump  1.66    1.57    1.68   1.57    1.61    1.60   1.62   \n",
      "4    Kamala Harris  2.50    2.38    2.43   2.40    2.30    2.40   2.38   \n",
      "..             ...   ...     ...     ...    ...     ...     ...    ...   \n",
      "151    Republicans  0.00   15.00    0.00  10.00    9.00    9.00   0.00   \n",
      "152      Democrats  0.00    1.01    0.00   1.01    1.01    1.01   0.00   \n",
      "153    Republicans  0.00   26.00    0.00  19.00   17.00   26.00   0.00   \n",
      "154      Democrats  0.00    1.01    0.00   1.01    1.01    1.01   0.00   \n",
      "155    Republicans  0.00   26.00    0.00  19.00   15.00   21.00   0.00   \n",
      "\n",
      "         FB      FR  ...    S6     SI      SK     SX      UN     VC      VT  \\\n",
      "0      1.62    1.62  ...  0.00   1.62    1.62   1.62    1.60   1.61    1.80   \n",
      "1      2.25    2.30  ...  0.00   2.30    2.25   2.30    2.40   2.25    2.00   \n",
      "2    101.00  151.00  ...  0.00  67.00  201.00  67.00  101.00  81.00  126.00   \n",
      "3      1.62    1.62  ...  1.70   1.62    1.62   1.62    1.60   1.61    1.62   \n",
      "4      2.38    2.38  ...  2.25   2.30    2.25   2.30    2.40   2.25    2.25   \n",
      "..      ...     ...  ...   ...    ...     ...    ...     ...    ...     ...   \n",
      "151    9.50   13.00  ...  0.00   0.00   10.00   0.00    9.00   0.00    0.00   \n",
      "152    1.01    1.01  ...  0.00   0.00    1.02   0.00    1.01   0.00    0.00   \n",
      "153   15.00   21.00  ...  0.00   0.00   17.00   0.00   26.00   0.00    0.00   \n",
      "154    1.01    1.01  ...  0.00   0.00    1.02   0.00    1.01   0.00    0.00   \n",
      "155   15.00   21.00  ...  0.00   0.00   17.00   0.00   21.00   0.00    0.00   \n",
      "\n",
      "         WA     WH                                                URL  \n",
      "0      1.61   1.62  https://www.oddschecker.com/politics/us-politi...  \n",
      "1      2.30   2.38  https://www.oddschecker.com/politics/us-politi...  \n",
      "2    101.00  51.00  https://www.oddschecker.com/politics/us-politi...  \n",
      "3      1.57   1.62  https://www.oddschecker.com/politics/us-politi...  \n",
      "4      2.38   2.38  https://www.oddschecker.com/politics/us-politi...  \n",
      "..      ...    ...                                                ...  \n",
      "151   15.00  10.00  https://www.oddschecker.com/politics/us-politi...  \n",
      "152    1.01   1.01  https://www.oddschecker.com/politics/us-politi...  \n",
      "153   26.00  17.00  https://www.oddschecker.com/politics/us-politi...  \n",
      "154    1.01   1.01  https://www.oddschecker.com/politics/us-politi...  \n",
      "155   26.00  15.00  https://www.oddschecker.com/politics/us-politi...  \n",
      "\n",
      "[156 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "all_data_oc = pd.concat(dataframes_list_oc).reset_index()\n",
    "all_data_oc.rename(columns={'index': 'Bet'}, inplace=True)\n",
    "\n",
    "print(all_data_oc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betfair data\n",
    "Next to grab the data from the Betfair Exchange API for political markets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load login credentials\n",
    "load_dotenv()\n",
    "\n",
    "bf_usr = os.getenv(\"BF_LOGIN\")\n",
    "bf_pass = os.getenv(\"BF_PASS\")\n",
    "bf_api = os.getenv(\"BF_API_KEY\")\n",
    "#bf_session = os.getenv(\"BF_SESSION\")\n",
    "bf_certs_path = '../certs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LoginResource>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to betfair client\n",
    "client = APIClient(bf_usr, bf_pass, app_key=bf_api, certs=bf_certs_path)\n",
    "client.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The market ID's are extracted given the event ID for politcal bets, followed by getting the bid/ask price and size for each market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Market Catalogues and create mappings for Selection and Market Names\n",
    "market_filter = betfairlightweight.filters.market_filter(\n",
    "    event_type_ids=['2378961'],  # Politics event type\n",
    ")\n",
    "\n",
    "# Get market catalogues, including runners\n",
    "market_catalogues = client.betting.list_market_catalogue(\n",
    "    filter=market_filter,\n",
    "    max_results=100,  # Adjust this as needed\n",
    "    market_projection=['RUNNER_DESCRIPTION']  # Include runner descriptions to get selection names\n",
    ")\n",
    "\n",
    "# Extract market IDs and create mappings\n",
    "market_ids = [market.market_id for market in market_catalogues]\n",
    "\n",
    "selection_mapping = {}\n",
    "market_name_mapping = {}\n",
    "\n",
    "for market in market_catalogues:\n",
    "    market_name_mapping[market.market_id] = market.market_name  # Map market_id to market_name\n",
    "    for runner in market.runners:\n",
    "        selection_mapping[runner.selection_id] = runner.runner_name  # Map selection_id to selection_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process runner books and include selection and market names\n",
    "def process_runner_books(runner_books, selection_mapping, market_name, market_id):\n",
    "    best_back_prices = [\n",
    "        runner_book.ex.available_to_back[0]['price'] if runner_book.ex.available_to_back else 1.01\n",
    "        for runner_book in runner_books\n",
    "    ]\n",
    "    best_back_sizes = [\n",
    "        runner_book.ex.available_to_back[0]['size'] if runner_book.ex.available_to_back else 1.01\n",
    "        for runner_book in runner_books\n",
    "    ]\n",
    "\n",
    "    best_lay_prices = [\n",
    "        runner_book.ex.available_to_lay[0]['price'] if runner_book.ex.available_to_lay else 1000.0\n",
    "        for runner_book in runner_books\n",
    "    ]\n",
    "    best_lay_sizes = [\n",
    "        runner_book.ex.available_to_lay[0]['size'] if runner_book.ex.available_to_lay else 1.01\n",
    "        for runner_book in runner_books\n",
    "    ]\n",
    "\n",
    "    selection_ids = [runner_book.selection_id for runner_book in runner_books]\n",
    "    selection_names = [selection_mapping.get(runner_book.selection_id, \"Unknown\") for runner_book in runner_books]\n",
    "    last_prices_traded = [runner_book.last_price_traded for runner_book in runner_books]\n",
    "    total_matched = [runner_book.total_matched for runner_book in runner_books]\n",
    "    statuses = [runner_book.status for runner_book in runner_books]\n",
    "    scratching_datetimes = [runner_book.removal_date for runner_book in runner_books]\n",
    "    adjustment_factors = [runner_book.adjustment_factor for runner_book in runner_books]\n",
    "\n",
    "    market_id = str(market_id)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Market ID': market_id,\n",
    "        'Market Name': market_name,\n",
    "        'Selection ID': selection_ids,\n",
    "        'Selection Name': selection_names,\n",
    "        'Best Back Price': best_back_prices,\n",
    "        'Best Back Size': best_back_sizes,\n",
    "        'Best Lay Price': best_lay_prices,\n",
    "        'Best Lay Size': best_lay_sizes,\n",
    "        'Last Price Traded': last_prices_traded,\n",
    "        'Total Matched': total_matched,\n",
    "        'Status': statuses,\n",
    "        'Removal Date': scratching_datetimes,\n",
    "        'Adjustment Factor': adjustment_factors\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Market ID         Market Name  Selection ID      Selection Name  \\\n",
      "0    1.170273835  Next Labour Leader      11149003       Wes Streeting   \n",
      "1    1.170273835  Next Labour Leader       5859542       Rachel Reeves   \n",
      "2    1.170273835  Next Labour Leader       2601290        Andy Burnham   \n",
      "3    1.170273835  Next Labour Leader      28275586  Bridget Phillipson   \n",
      "4    1.170273835  Next Labour Leader       1288344       Yvette Cooper   \n",
      "..           ...                 ...           ...                 ...   \n",
      "579  1.229997508              Kansas       1171580         Republicans   \n",
      "580  1.230123858               Texas       1171581           Democrats   \n",
      "581  1.230123858               Texas       1171580         Republicans   \n",
      "582  1.229997507                Iowa       1171581           Democrats   \n",
      "583  1.229997507                Iowa       1171580         Republicans   \n",
      "\n",
      "     Best Back Price  Best Back Size  Best Lay Price  Best Lay Size  \\\n",
      "0               8.60           26.71            9.00          16.99   \n",
      "1               7.40           16.33            9.80          10.00   \n",
      "2              12.50           11.99           17.00          13.53   \n",
      "3              14.00           15.76           20.00          14.99   \n",
      "4              10.50           13.99           16.00          10.88   \n",
      "..               ...             ...             ...            ...   \n",
      "579             1.01         8834.72            1.02        3010.53   \n",
      "580            15.00           32.17           16.00          37.90   \n",
      "581             1.06         1617.61            1.08        1458.35   \n",
      "582            17.00          100.01           18.00          10.00   \n",
      "583             1.05         2525.06            1.06         255.94   \n",
      "\n",
      "     Last Price Traded  Total Matched  Status Removal Date Adjustment Factor  \n",
      "0                 8.80            0.0  ACTIVE         None              None  \n",
      "1                 8.60            0.0  ACTIVE         None              None  \n",
      "2                16.00            0.0  ACTIVE         None              None  \n",
      "3                18.50            0.0  ACTIVE         None              None  \n",
      "4                13.50            0.0  ACTIVE         None              None  \n",
      "..                 ...            ...     ...          ...               ...  \n",
      "579               1.01            0.0  ACTIVE         None              None  \n",
      "580              13.00            0.0  ACTIVE         None              None  \n",
      "581               1.07            0.0  ACTIVE         None              None  \n",
      "582              18.00            0.0  ACTIVE         None              None  \n",
      "583               1.06            0.0  ACTIVE         None              None  \n",
      "\n",
      "[584 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/kjxldrfs36qgygzmg25sqy100000gn/T/ipykernel_14957/2125063919.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_data_df = pd.concat(dataframes_list_bf, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a price filter for market data\n",
    "price_filter = betfairlightweight.filters.price_projection(\n",
    "    price_data=['EX_BEST_OFFERS']\n",
    ")\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes_list_bf = []\n",
    "\n",
    "# Loop through each market ID and fetch market book data\n",
    "for market_id in market_ids:\n",
    "    # Request market book for each market ID\n",
    "    market_books = client.betting.list_market_book(\n",
    "        market_ids=[market_id],\n",
    "        price_projection=price_filter\n",
    "    )\n",
    "    \n",
    "    # Ensure that market books were returned\n",
    "    if market_books:\n",
    "        # Process the first market book (only one is requested)\n",
    "        market_book = market_books[0]\n",
    "        \n",
    "        # Get market name using the market_id\n",
    "        market_name = market_name_mapping[market_id]\n",
    "        \n",
    "        # Process runner books and store in DataFrame, including selection names and market names\n",
    "        runners_df = process_runner_books(market_book.runners, selection_mapping, market_name, market_id)\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dataframes_list_bf.append(runners_df)\n",
    "\n",
    "# Optionally, you can concatenate all dataframes into a single dataframe\n",
    "all_data_df = pd.concat(dataframes_list_bf, ignore_index=True)\n",
    "\n",
    "# Display or process the combined DataFrame as needed\n",
    "print(all_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bet matching\n",
    "An attempt to automate matching the market names of betfair to oddschecker using cosine similarity. It has some success but as it's unlikely that markets will be added or removed frequently, it'll probably be easier to manually match the markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Extract market names from Betfair data\n",
    "betfair_market_names = list(set(all_data_df['Market Name'].tolist()))\n",
    "\n",
    "# Combine all market names for vectorization\n",
    "all_market_names = betfair_market_names + urls\n",
    "\n",
    "# Vectorize the market names using TF-IDF\n",
    "vectorizer = TfidfVectorizer().fit_transform(all_market_names)\n",
    "vectors = vectorizer.toarray()\n",
    "\n",
    "# Calculate cosine similarity between Betfair and Oddschecker markets\n",
    "cosine_sim_matrix = cosine_similarity(vectors[:len(betfair_market_names)], vectors[len(betfair_market_names):])\n",
    "\n",
    "# Find the best matches for each Betfair market\n",
    "matches = []\n",
    "for i, betfair_name in enumerate(betfair_market_names):\n",
    "    similarity_scores = cosine_sim_matrix[i]\n",
    "    best_match_idx = np.argmax(similarity_scores)\n",
    "    best_match_score = similarity_scores[best_match_idx]\n",
    "    best_match_name = urls[best_match_idx]\n",
    "    matches.append({\n",
    "        'Betfair Market Name': betfair_name,\n",
    "        'Oddschecker Market Name': best_match_name,\n",
    "        'Similarity Score': best_match_score\n",
    "    })\n",
    "\n",
    "# Convert matches to DataFrame for easier review\n",
    "matches_df = pd.DataFrame(matches)\n",
    "\n",
    "# Filter out rows with a similarity score of 0\n",
    "matches_df_filtered = matches_df[matches_df['Similarity Score'] > 0]\n",
    "\n",
    "# Sort the DataFrame by similarity score in descending order\n",
    "matches_df_filtered = matches_df_filtered.sort_values(by='Similarity Score', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(matches_df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mappings are loaded from data/markets.csv as opposed to the cosine similarity matching above. A fuzzy match is then carried out between the 'Selection Name' from the betfair data and 'Bet' from the oddschecker data as the name of the Bets may not be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "from rapidfuzz import process\n",
    "\n",
    "# Load the mapping CSV file and ensure Market ID is a string for matching consistency\n",
    "mapping_df = pd.read_csv(\"../data/markets.csv\")\n",
    "mapping_df['Market ID'] = mapping_df['Market ID'].astype(str)\n",
    "\n",
    "# Load the first DataFrame (Betfair data) and ensure Market ID is a string\n",
    "betfair_df = all_data_df\n",
    "betfair_df['Market ID'] = betfair_df['Market ID'].astype(str)\n",
    "\n",
    "# Load the second DataFrame (Oddschecker data)\n",
    "oddschecker_df = all_data_oc\n",
    "\n",
    "# Normalize the 'Selection Name' and 'Bet' columns for better matching\n",
    "betfair_df['Selection Name Normalized'] = betfair_df['Selection Name'].str.lower().str.strip()\n",
    "oddschecker_df['Bet Normalized'] = oddschecker_df['Bet'].str.lower().str.strip()\n",
    "\n",
    "# Initialize a list to collect all results\n",
    "all_results = []\n",
    "\n",
    "# Iterate over each market in the mapping DataFrame\n",
    "for index, row in mapping_df.iterrows():\n",
    "    market_id = row['Market ID']\n",
    "    url = row['URL']\n",
    "    \n",
    "    # Skip markets without a URL\n",
    "    if pd.isna(url) or url.strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    # Filter Betfair DataFrame to only include rows with the current Market ID\n",
    "    betfair_filtered_df = betfair_df[betfair_df['Market ID'] == market_id]\n",
    "    \n",
    "    # Filter Oddschecker DataFrame to only include rows with the current URL\n",
    "    oddschecker_filtered_df = oddschecker_df[oddschecker_df['URL'] == url]\n",
    "    \n",
    "    # Skip if there are no corresponding entries in either filtered DataFrame\n",
    "    if betfair_filtered_df.empty or oddschecker_filtered_df.empty:\n",
    "        continue\n",
    "    \n",
    "    # Create a function to find the best match for each 'Selection Name'\n",
    "    def match_bets(selection_name, bet_choices):\n",
    "        match, score, _ = process.extractOne(selection_name, bet_choices, scorer=fuzz.token_sort_ratio)\n",
    "        return match, score\n",
    "\n",
    "    # Apply the matching function to each 'Selection Name' in the filtered Betfair DataFrame\n",
    "    bet_choices = oddschecker_filtered_df['Bet Normalized'].tolist()\n",
    "    matches = betfair_filtered_df['Selection Name Normalized'].apply(lambda x: match_bets(x, bet_choices))\n",
    "\n",
    "    # Add match results to betfair_filtered_df\n",
    "    betfair_filtered_df['Best Match Bet'] = matches.apply(lambda x: x[0])\n",
    "    betfair_filtered_df['Similarity Score'] = matches.apply(lambda x: x[1])\n",
    "\n",
    "    # Filter matches based on a similarity threshold (e.g., 80)\n",
    "    threshold = 80\n",
    "    filtered_matches_df = betfair_filtered_df[betfair_filtered_df['Similarity Score'] >= threshold]\n",
    "    \n",
    "    # Merge with the filtered Oddschecker DataFrame on 'URL' and 'Best Match Bet'\n",
    "    final_filtered_df = pd.merge(filtered_matches_df, oddschecker_filtered_df, left_on=['Best Match Bet'], right_on=['Bet'], how='left')\n",
    "    \n",
    "    # Drop temporary columns and finalize DataFrame\n",
    "    final_filtered_df = final_filtered_df.drop(columns=['Selection Name Normalized', 'Bet Normalized', 'Best Match Bet', 'Similarity Score'])\n",
    "    \n",
    "    # Append the results to the all_results list\n",
    "    all_results.append(final_filtered_df)\n",
    "\n",
    "# Concatenate all the DataFrames in the list to create a single DataFrame\n",
    "final_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Display or save the final DataFrame as needed\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mapping CSV file and ensure Market ID is a string for matching consistency\n",
    "mapping_df = pd.read_csv(\"../data/markets.csv\")\n",
    "mapping_df['Market ID'] = mapping_df['Market ID'].astype(str)\n",
    "\n",
    "# Load the first DataFrame (Betfair data) and ensure Market ID is a string\n",
    "betfair_df = all_data_df\n",
    "betfair_df['Market ID'] = betfair_df['Market ID'].astype(str)\n",
    "\n",
    "# Load the second DataFrame (Oddschecker data)\n",
    "oddschecker_df = all_data_oc\n",
    "\n",
    "# Normalize the 'Selection Name' and 'Bet' columns for better matching\n",
    "betfair_df['Selection Name Normalized'] = betfair_df['Selection Name'].str.lower().str.strip()\n",
    "oddschecker_df['Bet Normalized'] = oddschecker_df['Bet'].str.lower().str.strip()\n",
    "\n",
    "# Initialize a list to collect all results\n",
    "all_results = []\n",
    "\n",
    "# Iterate over each market in the mapping DataFrame\n",
    "for index, row in mapping_df.iterrows():\n",
    "    market_id = row['Market ID']\n",
    "    url = row['URL']\n",
    "    \n",
    "    # Skip markets without a URL\n",
    "    if pd.isna(url) or url.strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    # Filter Betfair DataFrame to only include rows with the current Market ID\n",
    "    betfair_filtered_df = betfair_df[betfair_df['Market ID'] == market_id]\n",
    "    \n",
    "    # Filter Oddschecker DataFrame to only include rows with the current URL\n",
    "    oddschecker_filtered_df = oddschecker_df[oddschecker_df['URL'] == url]\n",
    "    \n",
    "    # Skip if there are no corresponding entries in either filtered DataFrame\n",
    "    if betfair_filtered_df.empty or oddschecker_filtered_df.empty:\n",
    "        continue\n",
    "    \n",
    "    # Perform direct matching of 'Selection Name Normalized' with 'Bet Normalized'\n",
    "    merged_df = pd.merge(\n",
    "        betfair_filtered_df,\n",
    "        oddschecker_filtered_df,\n",
    "        left_on='Selection Name Normalized',\n",
    "        right_on='Bet Normalized',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Drop unnecessary columns from the merged DataFrame\n",
    "    merged_df = merged_df.drop(columns=['Selection Name Normalized', 'Bet Normalized'])\n",
    "    \n",
    "    # Append the results to the all_results list\n",
    "    all_results.append(merged_df)\n",
    "\n",
    "# Concatenate all the DataFrames in the list to create a single DataFrame\n",
    "odds_df = pd.concat(all_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_arbitrage(df):\n",
    "    odds_columns = ['AKB', 'B3', 'BF', 'BY', 'CE', 'DP', 'EE', 'FB', 'FR', 'G5', 'KN', 'LD', 'LS', 'MA', 'N4', 'OE', 'PP', 'QN', 'S6', 'SI', 'SK', 'SX', 'UN', 'VC', 'VT', 'WA', 'WH']\n",
    "    #select_columns = ['Market Name', 'Selection Name', 'Odds to Lay Ratio', 'Best Back Price', 'Best Lay Price', 'Best Lay Size', 'Best Odds', 'Best Bookmaker', 'URL']\n",
    "\n",
    "    # Find the best odds and corresponding bookmaker\n",
    "    df['Best Odds'] = df[odds_columns].max(axis=1)\n",
    "    df['Best Bookmaker'] = df.apply(lambda row: ', '.join([col for col in odds_columns if row[col] == row['Best Odds']]), axis=1)\n",
    "\n",
    "    # Calculate the ratio of Best Odds to Best Lay Price\n",
    "    df['Odds to Lay Ratio'] = df.apply(lambda row: row['Best Odds'] / row['Best Lay Price'] if row['Best Odds'] <= 500 else 0, axis=1)\n",
    "\n",
    "    # Sort the DataFrame by the 'Odds to Lay Ratio' in descending order\n",
    "    df = df.sort_values(by='Odds to Lay Ratio', ascending=False)\n",
    "\n",
    "    # Convert necessary columns to float for calculations\n",
    "    df['Best Odds'] = df['Best Odds'].astype(float)\n",
    "    df['Best Lay Price'] = df['Best Lay Price'].astype(float)\n",
    "    df['Best Lay Size'] = df['Best Lay Size'].astype(float)\n",
    "\n",
    "    # Calculate Lay Liability\n",
    "    df['Lay Liability'] = (df['Best Lay Size'] * (df['Best Lay Price'] - 1)).round(2)\n",
    "\n",
    "    # Calculate Back Amount (B) for hedging\n",
    "    df['Back Amount'] = (df['Best Lay Size'] * df['Best Lay Price'] / (df['Best Odds'])).round(2)\n",
    "\n",
    "    # Calculate Profit\n",
    "    df['Profit If Outcome Happens'] = (df['Back Amount'] * (df['Best Odds'] - 1)) - df['Lay Liability']\n",
    "    df['Profit If Outcome Does Not Happen'] = df['Best Lay Size'] - df['Back Amount']\n",
    "\n",
    "    # Set Profit to the minimum of the two scenarios, rounded to 2 decimal places\n",
    "    df['Profit'] = df[['Profit If Outcome Happens', 'Profit If Outcome Does Not Happen']].min(axis=1).round(2)\n",
    "\n",
    "    # Set Profit to 0 if Best Odds > 500\n",
    "    df.loc[df['Best Odds'] > 500, 'Profit'] = 0\n",
    "\n",
    "    # Filter for potential arbitrage opportunities\n",
    "    arb_opportunities = df[df['Odds to Lay Ratio'] > 1]\n",
    "\n",
    "    # Select and order the columns for the final DataFrame\n",
    "    cols = ['Market Name', 'Selection Name', 'Odds to Lay Ratio', 'Best Odds', 'Best Lay Price', 'Best Lay Size', 'Best Bookmaker',\n",
    "            'Lay Liability', 'Back Amount', 'Profit', 'URL']\n",
    "\n",
    "    return arb_opportunities[cols]\n",
    "\n",
    "arbitrage_opportunities = identify_arbitrage(odds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market Name</th>\n",
       "      <th>Selection Name</th>\n",
       "      <th>Odds to Lay Ratio</th>\n",
       "      <th>Best Odds</th>\n",
       "      <th>Best Lay Price</th>\n",
       "      <th>Best Lay Size</th>\n",
       "      <th>Best Bookmaker</th>\n",
       "      <th>Lay Liability</th>\n",
       "      <th>Back Amount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Next Labour Leader</td>\n",
       "      <td>Darren Jones</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>67.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>FB, PP</td>\n",
       "      <td>519.40</td>\n",
       "      <td>7.91</td>\n",
       "      <td>2.66</td>\n",
       "      <td>https://www.oddschecker.com/politics/british-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Election Winner</td>\n",
       "      <td>Kamala Harris</td>\n",
       "      <td>1.008065</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2402.36</td>\n",
       "      <td>AKB</td>\n",
       "      <td>3555.49</td>\n",
       "      <td>2383.14</td>\n",
       "      <td>19.22</td>\n",
       "      <td>https://www.oddschecker.com/politics/us-politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Will Election Winner lose Popular Vote?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.003650</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.74</td>\n",
       "      <td>148.85</td>\n",
       "      <td>AKB</td>\n",
       "      <td>259.00</td>\n",
       "      <td>148.31</td>\n",
       "      <td>0.54</td>\n",
       "      <td>https://www.oddschecker.com/politics/us-politi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Market Name Selection Name  Odds to Lay Ratio  \\\n",
       "8                        Next Labour Leader   Darren Jones           1.340000   \n",
       "58                          Election Winner  Kamala Harris           1.008065   \n",
       "81  Will Election Winner lose Popular Vote?            Yes           1.003650   \n",
       "\n",
       "    Best Odds  Best Lay Price  Best Lay Size Best Bookmaker  Lay Liability  \\\n",
       "8       67.00           50.00          10.60         FB, PP         519.40   \n",
       "58       2.50            2.48        2402.36            AKB        3555.49   \n",
       "81       2.75            2.74         148.85            AKB         259.00   \n",
       "\n",
       "    Back Amount  Profit                                                URL  \n",
       "8          7.91    2.66  https://www.oddschecker.com/politics/british-p...  \n",
       "58      2383.14   19.22  https://www.oddschecker.com/politics/us-politi...  \n",
       "81       148.31    0.54  https://www.oddschecker.com/politics/us-politi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(arbitrage_opportunities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Polymarket and Predictit\n",
    "#### Predictit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import json\n",
    "\n",
    "# PredictIt API function\n",
    "async def fetch_predictit_data():\n",
    "    url = \"https://www.predictit.org/api/marketdata/all/\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            data = await response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                               name  \\\n",
      "0  6867  Which party will win the 2024 U.S. presidentia...   \n",
      "1  7013    Will a woman be elected U.S. president in 2024?   \n",
      "2  7136       Will Joe Biden resign during his first term?   \n",
      "3  7419       Will Kamala Harris be the 47th US president?   \n",
      "4  7456    Who will win the 2024 US presidential election?   \n",
      "5  8070  Which party will win the 2024 US Senate electi...   \n",
      "6  8072  Which party will win Georgia in the 2024 presi...   \n",
      "7  8075  Which party will win the 2024 US Senate electi...   \n",
      "8  8076  Which party will win Wisconsin in the 2024 pre...   \n",
      "9  8077  What will be the Electoral College margin in t...   \n",
      "\n",
      "                                  shortName  \\\n",
      "0  Which party wins the presidency in 2024?   \n",
      "1          Woman president elected in 2024?   \n",
      "2  Will Biden resign during his first term?   \n",
      "3             Harris the 47th US president?   \n",
      "4        2024 presidential election winner?   \n",
      "5  Which party will win the AZ Senate race?   \n",
      "6          Which party will win GA in 2024?   \n",
      "7  Which party will win the OH Senate race?   \n",
      "8          Which party will win WI in 2024?   \n",
      "9         Electoral College margin in 2024?   \n",
      "\n",
      "                                               image  \\\n",
      "0  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "1  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "2  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "3  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "4  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "5  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "6  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "7  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "8  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "9  https://az620379.vo.msecnd.net/images/Markets/...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.predictit.org/markets/detail/6867/...   \n",
      "1  https://www.predictit.org/markets/detail/7013/...   \n",
      "2  https://www.predictit.org/markets/detail/7136/...   \n",
      "3  https://www.predictit.org/markets/detail/7419/...   \n",
      "4  https://www.predictit.org/markets/detail/7456/...   \n",
      "5  https://www.predictit.org/markets/detail/8070/...   \n",
      "6  https://www.predictit.org/markets/detail/8072/...   \n",
      "7  https://www.predictit.org/markets/detail/8075/...   \n",
      "8  https://www.predictit.org/markets/detail/8076/...   \n",
      "9  https://www.predictit.org/markets/detail/8077/...   \n",
      "\n",
      "                                           contracts  \\\n",
      "0  [{'id': 23546, 'dateEnd': 'NA', 'image': 'http...   \n",
      "1  [{'id': 24594, 'dateEnd': 'NA', 'image': 'http...   \n",
      "2  [{'id': 25232, 'dateEnd': '2025-01-20T11:59:00...   \n",
      "3  [{'id': 27224, 'dateEnd': 'NA', 'image': 'http...   \n",
      "4  [{'id': 27485, 'dateEnd': 'NA', 'image': 'http...   \n",
      "5  [{'id': 31257, 'dateEnd': 'NA', 'image': 'http...   \n",
      "6  [{'id': 31261, 'dateEnd': 'NA', 'image': 'http...   \n",
      "7  [{'id': 31297, 'dateEnd': 'NA', 'image': 'http...   \n",
      "8  [{'id': 31300, 'dateEnd': 'NA', 'image': 'http...   \n",
      "9  [{'id': 31306, 'dateEnd': 'NA', 'image': 'http...   \n",
      "\n",
      "                    timeStamp status  \n",
      "0  2024-10-17T12:16:00.829398   Open  \n",
      "1  2024-10-17T12:16:00.829398   Open  \n",
      "2  2024-10-17T12:16:00.829398   Open  \n",
      "3  2024-10-17T12:16:00.829398   Open  \n",
      "4  2024-10-17T12:16:00.829398   Open  \n",
      "5  2024-10-17T12:16:00.829398   Open  \n",
      "6  2024-10-17T12:16:00.829398   Open  \n",
      "7  2024-10-17T12:16:00.829398   Open  \n",
      "8  2024-10-17T12:16:00.829398   Open  \n",
      "9  2024-10-17T12:16:00.829398   Open  \n"
     ]
    }
   ],
   "source": [
    "predictit_data = await fetch_predictit_data()\n",
    "\n",
    "predictit_df = pd.json_normalize(predictit_data['markets'])\n",
    "\n",
    "print(predictit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polymarket\n",
    "ClobClient connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_clob_client.client import ClobClient\n",
    "\n",
    "# Polymarket API function\n",
    "host = \"https://clob.polymarket.com\"\n",
    "key = os.getenv(\"PK\")\n",
    "chain_id = 137  # Polygon Mainnet chain ID\n",
    "# Ensure the private key is loaded correctly\n",
    "if not key:\n",
    "    raise ValueError(\"Private key not found. Please set PK in the environment variables.\")\n",
    "# Initialize the client with your private key\n",
    "client = ClobClient(host, key=key, chain_id=chain_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Market data from https://gamma-api.polymarket.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Market ID                                  Title              End Date  \\\n",
      "0      903193      Presidential Election Winner 2024  2024-11-04T12:00:00Z   \n",
      "9      903193      Presidential Election Winner 2024  2024-11-04T12:00:00Z   \n",
      "1      903193      Presidential Election Winner 2024  2024-11-04T12:00:00Z   \n",
      "16     903193      Presidential Election Winner 2024  2024-11-04T12:00:00Z   \n",
      "14     903193      Presidential Election Winner 2024  2024-11-04T12:00:00Z   \n",
      "..        ...                                    ...                   ...   \n",
      "204     11413   Next UK leader of the Conservatives?  2024-12-31T12:00:00Z   \n",
      "203     11413   Next UK leader of the Conservatives?  2024-12-31T12:00:00Z   \n",
      "210    903669  Missouri Presidential Election Winner  2024-11-05T12:00:00Z   \n",
      "209    903669  Missouri Presidential Election Winner  2024-11-05T12:00:00Z   \n",
      "208    903669  Missouri Presidential Election Winner  2024-11-05T12:00:00Z   \n",
      "\n",
      "     Overall Liquidity  Overall Volume  Overall Volume 24hr  \\\n",
      "0         4.975215e+08    2.094772e+09         3.017168e+07   \n",
      "9         4.975215e+08    2.094772e+09         3.017168e+07   \n",
      "1         4.975215e+08    2.094772e+09         3.017168e+07   \n",
      "16        4.975215e+08    2.094772e+09         3.017168e+07   \n",
      "14        4.975215e+08    2.094772e+09         3.017168e+07   \n",
      "..                 ...             ...                  ...   \n",
      "204       1.068892e+05    3.819846e+06         7.055158e+05   \n",
      "203       1.068892e+05    3.819846e+06         7.055158e+05   \n",
      "210       3.197100e+05    1.090990e+06         6.828805e+05   \n",
      "209       3.197100e+05    1.090990e+06         6.828805e+05   \n",
      "208       3.197100e+05    1.090990e+06         6.828805e+05   \n",
      "\n",
      "                                          Bet Question  Bet Liquidity  \\\n",
      "0    Will Donald Trump win the 2024 US Presidential...   2.887125e+06   \n",
      "9    Will Elizabeth Warren win the 2024 US Presiden...   4.488723e+07   \n",
      "1    Will Joe Biden win the 2024 US Presidential El...   2.911274e+07   \n",
      "16   Will Hillary Clinton win the 2024 US President...   2.844823e+07   \n",
      "14   Will Kanye West win the 2024 US Presidential E...   4.498342e+07   \n",
      "..                                                 ...            ...   \n",
      "204        Priti Patel next Conservative party leader?   1.126726e+04   \n",
      "203        Jeremy Hunt next Conservative party leader?   1.128342e+04   \n",
      "210  Will a Republican win Missouri Presidential El...   1.063473e+05   \n",
      "209  Will a Democrat win Missouri Presidential Elec...   1.265557e+05   \n",
      "208  Will a candidate from another party win Missou...   8.680705e+04   \n",
      "\n",
      "       Bet Volume  Bet Volume 24hr  Yes Price  No Price  \n",
      "0    6.413322e+08     1.647102e+07     0.5975    0.4025  \n",
      "9    1.438554e+07     1.365000e+04     0.0005    0.9995  \n",
      "1    6.038026e+07     2.029030e+06     0.0005    0.9995  \n",
      "16   9.215241e+07     4.410070e+03     0.0005    0.9995  \n",
      "14   8.929560e+06     4.310000e+03     0.0005    0.9995  \n",
      "..            ...              ...        ...       ...  \n",
      "204  2.262885e+05     5.341310e+02     0.0015    0.9985  \n",
      "203  2.727761e+05     2.513510e+02     0.0015    0.9985  \n",
      "210  2.260092e+05     7.059288e+03     0.9935    0.0065  \n",
      "209  9.082332e+04     8.006000e+00     0.0060    0.9940  \n",
      "208  7.741575e+05     6.758132e+05     0.0015    0.9985  \n",
      "\n",
      "[251 rows x 12 columns]\n",
      "\n",
      "Basic Statistics:\n",
      "       Overall Liquidity  Overall Volume  Overall Volume 24hr  Bet Liquidity  \\\n",
      "count       2.510000e+02    2.510000e+02         2.510000e+02   2.510000e+02   \n",
      "mean        4.307117e+07    2.111926e+08         4.984482e+06   2.534363e+06   \n",
      "std         1.248744e+08    5.184494e+08         7.727183e+06   8.201317e+06   \n",
      "min         1.068892e+05    1.090990e+06         2.553328e+05   0.000000e+00   \n",
      "25%         2.116384e+06    1.278533e+07         8.935078e+05   6.444385e+04   \n",
      "50%         2.589208e+06    3.680093e+07         1.643331e+06   1.282936e+05   \n",
      "75%         7.259713e+06    1.110986e+08         3.464566e+06   3.657637e+05   \n",
      "max         4.975215e+08    2.094772e+09         3.017168e+07   4.498342e+07   \n",
      "\n",
      "         Bet Volume  Bet Volume 24hr   Yes Price    No Price  \n",
      "count  2.510000e+02     2.510000e+02  251.000000  251.000000  \n",
      "mean   1.257205e+07     3.047364e+05    0.072667    0.927333  \n",
      "std    5.265301e+07     1.627754e+06    0.169980    0.169980  \n",
      "min    3.467889e+03     0.000000e+00    0.000000    0.006500  \n",
      "25%    3.027484e+05     3.114183e+03    0.002500    0.945000  \n",
      "50%    2.192095e+06     1.365000e+04    0.007500    0.992500  \n",
      "75%    5.394324e+06     7.870107e+04    0.055000    0.997500  \n",
      "max    6.413322e+08     1.741286e+07    0.993500    1.000000  \n",
      "\n",
      "Top 5 Markets by Overall Volume:\n",
      "                                Title  \\\n",
      "0   Presidential Election Winner 2024   \n",
      "9   Presidential Election Winner 2024   \n",
      "1   Presidential Election Winner 2024   \n",
      "16  Presidential Election Winner 2024   \n",
      "14  Presidential Election Winner 2024   \n",
      "\n",
      "                                         Bet Question  Overall Volume  \\\n",
      "0   Will Donald Trump win the 2024 US Presidential...    2.094772e+09   \n",
      "9   Will Elizabeth Warren win the 2024 US Presiden...    2.094772e+09   \n",
      "1   Will Joe Biden win the 2024 US Presidential El...    2.094772e+09   \n",
      "16  Will Hillary Clinton win the 2024 US President...    2.094772e+09   \n",
      "14  Will Kanye West win the 2024 US Presidential E...    2.094772e+09   \n",
      "\n",
      "      Bet Volume  Yes Price  No Price  \n",
      "0   6.413322e+08     0.5975    0.4025  \n",
      "9   1.438554e+07     0.0005    0.9995  \n",
      "1   6.038026e+07     0.0005    0.9995  \n",
      "16  9.215241e+07     0.0005    0.9995  \n",
      "14  8.929560e+06     0.0005    0.9995  \n",
      "\n",
      "Implied Probabilities for Top 5 Bets by Volume:\n",
      "                                Title  \\\n",
      "0   Presidential Election Winner 2024   \n",
      "7   Presidential Election Winner 2024   \n",
      "13  Presidential Election Winner 2024   \n",
      "15  Presidential Election Winner 2024   \n",
      "4   Presidential Election Winner 2024   \n",
      "\n",
      "                                         Bet Question  \\\n",
      "0   Will Donald Trump win the 2024 US Presidential...   \n",
      "7   Will Kamala Harris win the 2024 US Presidentia...   \n",
      "13  Will any other Republican Politician win the 2...   \n",
      "15  Will Michelle Obama win the 2024 US Presidenti...   \n",
      "4   Will Robert F. Kennedy Jr. win the 2024 US Pre...   \n",
      "\n",
      "    Implied Probability (Yes)  Implied Probability (No)  \n",
      "0                      0.5975                    0.4025  \n",
      "7                      0.3995                    0.6005  \n",
      "13                     0.0015                    0.9985  \n",
      "15                     0.0005                    0.9995  \n",
      "4                      0.0005                    0.9995  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import ast\n",
    "\n",
    "# Fetch data from the Gamma API\n",
    "r = requests.get(\"https://gamma-api.polymarket.com/events?closed=false\")\n",
    "response = r.json()\n",
    "\n",
    "# Function to extract overall market data\n",
    "def extract_overall_market_data(market):\n",
    "    return {\n",
    "        'Market ID': market.get('id', 'N/A'),\n",
    "        'Title': market.get('title', 'N/A'),\n",
    "        'End Date': market.get('endDate', 'N/A'),\n",
    "        'Overall Liquidity': float(market.get('liquidity', 0)),\n",
    "        'Overall Volume': float(market.get('volume', 0)),\n",
    "        'Overall Volume 24hr': float(market.get('volume24hr', 0)),\n",
    "    }\n",
    "\n",
    "# Function to extract individual bet data\n",
    "def extract_bet_data(bet):\n",
    "    outcome_prices_str = bet.get('outcomePrices', '[\"N/A\", \"N/A\"]')\n",
    "    try:\n",
    "        outcome_prices = ast.literal_eval(outcome_prices_str)\n",
    "        yes_price = float(outcome_prices[0]) if len(outcome_prices) > 0 else None\n",
    "        no_price = float(outcome_prices[1]) if len(outcome_prices) > 1 else None\n",
    "    except (ValueError, SyntaxError):\n",
    "        yes_price = None\n",
    "        no_price = None\n",
    "\n",
    "    return {\n",
    "        'Bet Question': bet.get('question', 'N/A'),\n",
    "        'Bet Liquidity': float(bet.get('liquidity', 0)),\n",
    "        'Bet Volume': float(bet.get('volume', 0)),\n",
    "        'Bet Volume 24hr': float(bet.get('volume24hr', 0)),\n",
    "        'Yes Price': yes_price,\n",
    "        'No Price': no_price,\n",
    "    }\n",
    "\n",
    "# Extract data for all markets and bets\n",
    "market_data = []\n",
    "for market in response:\n",
    "    overall_data = extract_overall_market_data(market)\n",
    "    for bet in market.get('markets', []):\n",
    "        bet_data = extract_bet_data(bet)\n",
    "        combined_data = {**overall_data, **bet_data}\n",
    "        market_data.append(combined_data)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(market_data)\n",
    "\n",
    "# Sort by Overall Volume in descending order\n",
    "df = df.sort_values('Overall Volume', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Display top markets by volume\n",
    "print(\"\\nTop 5 Markets by Overall Volume:\")\n",
    "print(df.nlargest(5, 'Overall Volume')[['Title', 'Bet Question', 'Overall Volume', 'Bet Volume', 'Yes Price', 'No Price']])\n",
    "\n",
    "# Calculate and display implied probabilities\n",
    "df['Implied Probability (Yes)'] = df['Yes Price']\n",
    "df['Implied Probability (No)'] = df['No Price']\n",
    "\n",
    "print(\"\\nImplied Probabilities for Top 5 Bets by Volume:\")\n",
    "print(df.nlargest(5, 'Bet Volume')[['Title', 'Bet Question', 'Implied Probability (Yes)', 'Implied Probability (No)']])\n",
    "\n",
    "# Optional: Save to CSV\n",
    "# df.to_csv('polymarket_combined_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
