{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import concurrent.futures\n",
    "from selenium import webdriver\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import queue\n",
    "import threading\n",
    "\n",
    "import betfairlightweight\n",
    "from betfairlightweight import filters\n",
    "from betfairlightweight import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oddschecker data\n",
    "First extract the urls containing each of the odds tables from the oddschecker politics sitemap at https://www.oddschecker.com/sport/politics/sitemap.xml. However this does appear to be missing a bunch of markets for some reason, so it's simpler to manually update the list of markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 URLs.\n",
      "['https://www.oddschecker.com/politics/british-politics', 'https://www.oddschecker.com/politics/british-politics/next-uk-general-election/most-seats', 'https://www.oddschecker.com/politics/british-politics/next-conservative-leader', 'https://www.oddschecker.com/politics/us-politics', 'https://www.oddschecker.com/politics/us-politics/us-presidential-election/winner', 'https://www.oddschecker.com/politics/us-politics/us-state-betting/arizona', 'https://www.oddschecker.com/politics/us-politics/house-and-senate-elections-overall-control/senate-control', 'https://www.oddschecker.com/politics/us-politics/us-senate-elections/arizona', 'https://www.oddschecker.com/politics/european-politics', 'https://www.oddschecker.com/politics/european-politics/irish-politics/next-president', 'https://www.oddschecker.com/politics/european-politics/northern-irish-politics/next-united-ireland-referendum-result', 'https://www.oddschecker.com/politics/european-politics/scottish-politics/independence-referendum-result', 'https://www.oddschecker.com/politics/australian-politics', 'https://www.oddschecker.com/politics/australian-politics/federal-election/winner', 'https://www.oddschecker.com/politics/australian-politics/state-elections/queensland-state-election', 'https://www.oddschecker.com/politics/world-politics', 'https://www.oddschecker.com/politics/world-politics/45th-canadian-federal-election/next-sworn-in-government']\n"
     ]
    }
   ],
   "source": [
    "# Extract oddschecker politics market urls from sitemap\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\") \n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
    "\n",
    "service = Service(\"/opt/homebrew/bin/chromedriver\")\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# URL of the sitemap\n",
    "sitemap_url = \"https://www.oddschecker.com/sport/politics/sitemap.xml\"\n",
    "\n",
    "try:\n",
    "    # Load the sitemap page\n",
    "    driver.get(sitemap_url)\n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    xml_content = driver.page_source\n",
    "    soup = BeautifulSoup(xml_content, 'xml')\n",
    "\n",
    "    url_tags = soup.find_all('loc')\n",
    "    urls = [url_tag.text for url_tag in url_tags]\n",
    "\n",
    "    print(f\"Found {len(urls)} URLs.\")\n",
    "    print(urls)\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium is then used to load the pages and grab the page source. It's currently set to run five pages concurrently (using different headers) to help speed things up. The odds table is then extracted using beautifulsoup, putting the bet name and odds for each bookmaker into a dataframe. The data for the odds of each bookmaker seems to have a somewhat random class name in the html, but most contain \"bs\" or \"o\", so this is what's searched for in the table info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract odds data from a given URL\n",
    "def extract_odds(url, user_agent):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "    service = Service(\"/opt/homebrew/bin/chromedriver\")\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        # Navigate to the specific oddschecker page\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        time.sleep(6) \n",
    "\n",
    "        # Get the page source\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Odds table has id \"t1\"\n",
    "        odds_table = soup.find('tbody', id='t1')\n",
    "\n",
    "        if not odds_table:\n",
    "            print(f\"No odds table found for URL: {url}\")\n",
    "            return None  # Skip this URL if the table isn't found\n",
    "\n",
    "        # Extract each row and the data within\n",
    "        odds_data = []\n",
    "        bookmakers_set = set()\n",
    "\n",
    "        for row in odds_table.find_all('tr'):\n",
    "            bet_name = row.find('a', class_='popup').text.strip() \n",
    "            odds_dict = {'Bet': bet_name}\n",
    "            \n",
    "            # Find all td elements with odds information\n",
    "            for td in row.find_all('td', class_=lambda x: x and ('o' in x.split() or 'bs' in x.split())): \n",
    "                bookmaker = td.get('data-bk')  # Extract the bookmaker name\n",
    "                decimal_odds = td.get('data-odig')  # Extract the decimal odds value\n",
    "                if bookmaker and decimal_odds:  # Only add if both are present\n",
    "                    odds_dict[bookmaker] = float(decimal_odds)  # Convert odds to float\n",
    "                    bookmakers_set.add(bookmaker)\n",
    "            \n",
    "            odds_data.append(odds_dict)\n",
    "\n",
    "        # Create a DataFrame with all bookmakers as columns\n",
    "        df = pd.DataFrame(odds_data).set_index('Bet')\n",
    "\n",
    "        # Ensure all bookmakers are columns, even if some are missing in certain rows\n",
    "        df = df.reindex(columns=sorted(bookmakers_set))\n",
    "\n",
    "        # Add the URL as a column in the DataFrame\n",
    "        df['URL'] = url\n",
    "\n",
    "        return df\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The oddschecker sitemap seems to be missing some pages, so manually updated urls\n",
    "urls = [\n",
    "    \"https://www.oddschecker.com/politics/british-politics/next-labour-leader\",\n",
    "    \"https://www.oddschecker.com/politics/british-politics/next-conservative-leader\",\n",
    "    \"https://www.oddschecker.com/politics/australian-politics/state-elections/queensland-state-election\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/winner\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/winning-party\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/party-of-popular-vote-winner\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/gender-of-election-winner\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-presidential-election/election-winner-to-lose-popular-vote\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/mississippi\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/arizona\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/massachusetts\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/oklahoma\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/pennsylvania\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/oregon\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/minnesota\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/hawaii\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/alabama\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/texas\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/rhode-island\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/florida\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/delaware\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/connecticut\",\n",
    "    \"https://www.oddschecker.com/politics/us-politics/us-state-betting/colorado\"\n",
    "]\n",
    "\n",
    "# List of user agents to rotate\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15'\n",
    "]\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes_list_oc = []\n",
    "\n",
    "# Use ThreadPoolExecutor to process URLs in parallel in batches of 5\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for i, url in enumerate(urls):\n",
    "        user_agent = user_agents[i % len(user_agents)]  # Rotate user agents\n",
    "        futures.append(executor.submit(extract_odds, url, user_agent))\n",
    "\n",
    "        # Wait for each batch of 5 to complete before starting the next batch\n",
    "        if (i + 1) % 5 == 0 or i == len(urls) - 1:\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                df = future.result()\n",
    "                if df is not None:\n",
    "                    dataframes_list_oc.append(df)\n",
    "            futures = []  # Clear futures list for the next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Bet  AKB      B3      BF    BY     CE     DP    EE  \\\n",
      "0    Liberal National Party  0.0    1.08    1.07   0.0   0.00   0.00  0.00   \n",
      "1    Australian Labor Party  0.0    7.00    8.64   0.0   0.00   0.00  0.00   \n",
      "2           Any Other Party  0.0  151.00  147.00   0.0   0.00   0.00  0.00   \n",
      "3               Republicans  0.0    1.53    1.62   0.0   1.57   1.55  1.53   \n",
      "4                  Democrat  0.0    2.50    2.53   0.0   2.37   2.50  2.50   \n",
      "..                      ...  ...     ...     ...   ...    ...    ...   ...   \n",
      "134             Republicans  0.0   15.00    0.00  11.0  12.00  15.00  0.00   \n",
      "135               Democrats  0.0    1.01    0.00   1.0   1.01   1.01  0.00   \n",
      "136             Republicans  0.0   29.00    0.00  41.0  21.00  26.00  0.00   \n",
      "137               Democrats  0.0    1.01    0.00   1.0   1.01   1.01  0.00   \n",
      "138             Republicans  0.0   34.00    0.00  41.0  21.00  21.00  0.00   \n",
      "\n",
      "        FB     FR  ...   S6    SI     SK    SX      UN    VC     VT     WA  \\\n",
      "0     0.00   0.00  ...  0.0  0.00   0.00  0.00    1.08  0.00   0.00   0.00   \n",
      "1     0.00   0.00  ...  0.0  0.00   0.00  0.00    7.50  0.00   0.00   0.00   \n",
      "2     0.00   0.00  ...  0.0  0.00   0.00  0.00  101.00  0.00   0.00   0.00   \n",
      "3     1.57   1.57  ...  0.0  1.57   1.57  1.57    1.55  1.57   1.55   1.53   \n",
      "4     2.38   2.50  ...  0.0  2.40   2.38  2.40    2.50  2.38   2.35   2.50   \n",
      "..     ...    ...  ...  ...   ...    ...   ...     ...   ...    ...    ...   \n",
      "134  12.00  13.00  ...  0.0  0.00  10.00  0.00   15.00  0.00  11.00  15.00   \n",
      "135   1.01   1.01  ...  0.0  0.00   1.02  0.00    1.01  0.00   1.00   1.01   \n",
      "136  15.00  21.00  ...  0.0  0.00  17.00  0.00   26.00  0.00  19.00  26.00   \n",
      "137   1.01   1.01  ...  0.0  0.00   1.01  0.00    1.01  0.00   1.00   1.01   \n",
      "138  15.00  21.00  ...  0.0  0.00  17.00  0.00   21.00  0.00  19.00  26.00   \n",
      "\n",
      "        WH                                                URL  \n",
      "0     0.00  https://www.oddschecker.com/politics/australia...  \n",
      "1     0.00  https://www.oddschecker.com/politics/australia...  \n",
      "2     0.00  https://www.oddschecker.com/politics/australia...  \n",
      "3     1.57  https://www.oddschecker.com/politics/us-politi...  \n",
      "4     2.40  https://www.oddschecker.com/politics/us-politi...  \n",
      "..     ...                                                ...  \n",
      "134  10.00  https://www.oddschecker.com/politics/us-politi...  \n",
      "135   1.01  https://www.oddschecker.com/politics/us-politi...  \n",
      "136  26.00  https://www.oddschecker.com/politics/us-politi...  \n",
      "137   1.01  https://www.oddschecker.com/politics/us-politi...  \n",
      "138  17.00  https://www.oddschecker.com/politics/us-politi...  \n",
      "\n",
      "[139 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "all_data_oc = pd.concat(dataframes_list_oc).reset_index()\n",
    "all_data_oc.rename(columns={'index': 'Bet'}, inplace=True)\n",
    "\n",
    "print(all_data_oc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betfair data\n",
    "Next to grab the data from the Betfair Exchange API for political markets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load login credentials\n",
    "load_dotenv()\n",
    "\n",
    "bf_usr = os.getenv(\"BF_LOGIN\")\n",
    "bf_pass = os.getenv(\"BF_PASS\")\n",
    "bf_api = os.getenv(\"BF_API_KEY\")\n",
    "#bf_session = os.getenv(\"BF_SESSION\")\n",
    "bf_certs_path = '../certs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LoginResource>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to betfair client\n",
    "client = APIClient(bf_usr, bf_pass, app_key=bf_api, certs=bf_certs_path)\n",
    "client.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The market ID's are extracted given the event ID for politcal bets, followed by getting the bid/ask price and size for each market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Market Catalogues and create mappings for Selection and Market Names\n",
    "market_filter = betfairlightweight.filters.market_filter(\n",
    "    event_type_ids=['2378961'],  # Politics event type\n",
    ")\n",
    "\n",
    "# Get market catalogues, including runners\n",
    "market_catalogues = client.betting.list_market_catalogue(\n",
    "    filter=market_filter,\n",
    "    max_results=100,  # Adjust this as needed\n",
    "    market_projection=['RUNNER_DESCRIPTION']  # Include runner descriptions to get selection names\n",
    ")\n",
    "\n",
    "# Extract market IDs and create mappings\n",
    "market_ids = [market.market_id for market in market_catalogues]\n",
    "\n",
    "selection_mapping = {}\n",
    "market_name_mapping = {}\n",
    "\n",
    "for market in market_catalogues:\n",
    "    market_name_mapping[market.market_id] = market.market_name  # Map market_id to market_name\n",
    "    for runner in market.runners:\n",
    "        selection_mapping[runner.selection_id] = runner.runner_name  # Map selection_id to selection_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process runner books and include selection and market names\n",
    "def process_runner_books(runner_books, selection_mapping, market_name, market_id):\n",
    "    best_back_prices = [\n",
    "        runner_book.ex.available_to_back[0]['price'] if runner_book.ex.available_to_back else 1.01\n",
    "        for runner_book in runner_books\n",
    "    ]\n",
    "    best_back_sizes = [\n",
    "        runner_book.ex.available_to_back[0]['size'] if runner_book.ex.available_to_back else 1.01\n",
    "        for runner_book in runner_books\n",
    "    ]\n",
    "\n",
    "    best_lay_prices = [\n",
    "        runner_book.ex.available_to_lay[0]['price'] if runner_book.ex.available_to_lay else 1000.0\n",
    "        for runner_book in runner_books\n",
    "    ]\n",
    "    best_lay_sizes = [\n",
    "        runner_book.ex.available_to_lay[0]['size'] if runner_book.ex.available_to_lay else 1.01\n",
    "        for runner_book in runner_books\n",
    "    ]\n",
    "\n",
    "    selection_ids = [runner_book.selection_id for runner_book in runner_books]\n",
    "    selection_names = [selection_mapping.get(runner_book.selection_id, \"Unknown\") for runner_book in runner_books]\n",
    "    last_prices_traded = [runner_book.last_price_traded for runner_book in runner_books]\n",
    "    total_matched = [runner_book.total_matched for runner_book in runner_books]\n",
    "    statuses = [runner_book.status for runner_book in runner_books]\n",
    "    scratching_datetimes = [runner_book.removal_date for runner_book in runner_books]\n",
    "    adjustment_factors = [runner_book.adjustment_factor for runner_book in runner_books]\n",
    "\n",
    "    market_id = str(market_id)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Market ID': market_id,\n",
    "        'Market Name': market_name,\n",
    "        'Selection ID': selection_ids,\n",
    "        'Selection Name': selection_names,\n",
    "        'Best Back Price': best_back_prices,\n",
    "        'Best Back Size': best_back_sizes,\n",
    "        'Best Lay Price': best_lay_prices,\n",
    "        'Best Lay Size': best_lay_sizes,\n",
    "        'Last Price Traded': last_prices_traded,\n",
    "        'Total Matched': total_matched,\n",
    "        'Status': statuses,\n",
    "        'Removal Date': scratching_datetimes,\n",
    "        'Adjustment Factor': adjustment_factors\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Market ID         Market Name  Selection ID      Selection Name  \\\n",
      "0    1.170273835  Next Labour Leader      11149003       Wes Streeting   \n",
      "1    1.170273835  Next Labour Leader       5859542       Rachel Reeves   \n",
      "2    1.170273835  Next Labour Leader       2601290        Andy Burnham   \n",
      "3    1.170273835  Next Labour Leader      28275586  Bridget Phillipson   \n",
      "4    1.170273835  Next Labour Leader       1288344       Yvette Cooper   \n",
      "..           ...                 ...           ...                 ...   \n",
      "578  1.229997508              Kansas       1171580         Republicans   \n",
      "579  1.230123858               Texas       1171581           Democrats   \n",
      "580  1.230123858               Texas       1171580         Republicans   \n",
      "581  1.229997507                Iowa       1171581           Democrats   \n",
      "582  1.229997507                Iowa       1171580         Republicans   \n",
      "\n",
      "     Best Back Price  Best Back Size  Best Lay Price  Best Lay Size  \\\n",
      "0               6.00           11.64            7.00          10.01   \n",
      "1               9.20           12.00           14.50          11.48   \n",
      "2              13.50           12.17           17.00          11.64   \n",
      "3              17.00           10.11           20.00          14.74   \n",
      "4              11.50           13.00           16.00          12.43   \n",
      "..               ...             ...             ...            ...   \n",
      "578             1.01            1.01            1.02        7399.63   \n",
      "579            15.50           14.00           16.50          50.48   \n",
      "580             1.06          778.84            1.07         862.69   \n",
      "581            17.00          106.44           22.00          16.90   \n",
      "582             1.05           14.29            1.06        1150.00   \n",
      "\n",
      "     Last Price Traded  Total Matched  Status Removal Date Adjustment Factor  \n",
      "0                 6.00            0.0  ACTIVE         None              None  \n",
      "1                12.00            0.0  ACTIVE         None              None  \n",
      "2                17.00            0.0  ACTIVE         None              None  \n",
      "3                19.50            0.0  ACTIVE         None              None  \n",
      "4                13.50            0.0  ACTIVE         None              None  \n",
      "..                 ...            ...     ...          ...               ...  \n",
      "578               1.01            0.0  ACTIVE         None              None  \n",
      "579              16.00            0.0  ACTIVE         None              None  \n",
      "580               1.06            0.0  ACTIVE         None              None  \n",
      "581              20.00            0.0  ACTIVE         None              None  \n",
      "582               1.05            0.0  ACTIVE         None              None  \n",
      "\n",
      "[583 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/kjxldrfs36qgygzmg25sqy100000gn/T/ipykernel_94316/2125063919.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_data_df = pd.concat(dataframes_list_bf, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a price filter for market data\n",
    "price_filter = betfairlightweight.filters.price_projection(\n",
    "    price_data=['EX_BEST_OFFERS']\n",
    ")\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes_list_bf = []\n",
    "\n",
    "# Loop through each market ID and fetch market book data\n",
    "for market_id in market_ids:\n",
    "    # Request market book for each market ID\n",
    "    market_books = client.betting.list_market_book(\n",
    "        market_ids=[market_id],\n",
    "        price_projection=price_filter\n",
    "    )\n",
    "    \n",
    "    # Ensure that market books were returned\n",
    "    if market_books:\n",
    "        # Process the first market book (only one is requested)\n",
    "        market_book = market_books[0]\n",
    "        \n",
    "        # Get market name using the market_id\n",
    "        market_name = market_name_mapping[market_id]\n",
    "        \n",
    "        # Process runner books and store in DataFrame, including selection names and market names\n",
    "        runners_df = process_runner_books(market_book.runners, selection_mapping, market_name, market_id)\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dataframes_list_bf.append(runners_df)\n",
    "\n",
    "# Optionally, you can concatenate all dataframes into a single dataframe\n",
    "all_data_df = pd.concat(dataframes_list_bf, ignore_index=True)\n",
    "\n",
    "# Display or process the combined DataFrame as needed\n",
    "print(all_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bet matching\n",
    "An attempt to automate matching the market names of betfair to oddschecker using cosine similarity. It has some success but as it's unlikely that markets will be added or removed frequently, it'll probably be easier to manually match the markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Betfair Market Name  \\\n",
      "40                          Gender of Election Winner   \n",
      "75                                 Next Labour Leader   \n",
      "78                           Next Conservative Leader   \n",
      "66                       Party of Popular Vote Winner   \n",
      "23            Will Election Winner lose Popular Vote?   \n",
      "57                                       Rhode Island   \n",
      "1                                       Winning Party   \n",
      "10                                    Election Winner   \n",
      "59                                Popular Vote Winner   \n",
      "77                                      Massachusetts   \n",
      "24                                            Alabama   \n",
      "31                                            Arizona   \n",
      "20                                        Connecticut   \n",
      "35                                           Oklahoma   \n",
      "36                                             Hawaii   \n",
      "68                                             Oregon   \n",
      "39                                          Minnesota   \n",
      "16                                        Mississippi   \n",
      "4                                            Delaware   \n",
      "50                                              Texas   \n",
      "82                                       Pennsylvania   \n",
      "54                                            Florida   \n",
      "72                                Next Lib Dem Leader   \n",
      "45   Year Rishi Sunak replaced as Conservative Leader   \n",
      "84  Joe Manchin to be re-elected to the senate in ...   \n",
      "73                 Senate Control after 2024 Election   \n",
      "28                  House Control after 2024 Election   \n",
      "49  Will Joe Biden be impeached before 2024 Election?   \n",
      "29                  Number of Republican Senate Seats   \n",
      "55                             Harris Vote Percentage   \n",
      "32                              Trump Vote Percentage   \n",
      "22                            Trump Vote Percentage 2   \n",
      "81                           Harris Vote Percentage 2   \n",
      "61      Electoral College Vote Handicap - Trump +64.5   \n",
      "53      Electoral College Vote Handicap - Trump +99.5   \n",
      "38     Electoral College Vote Handicap - Harris +99.5   \n",
      "71     Electoral College Vote Handicap - Harris +64.5   \n",
      "74     Electoral College Vote Handicap - Harris +29.5   \n",
      "5       Electoral College Vote Handicap - Trump +29.5   \n",
      "\n",
      "                              Oddschecker Market Name  Similarity Score  \n",
      "40  https://www.oddschecker.com/politics/us-politi...          0.659184  \n",
      "75  https://www.oddschecker.com/politics/british-p...          0.641032  \n",
      "78  https://www.oddschecker.com/politics/british-p...          0.631243  \n",
      "66  https://www.oddschecker.com/politics/us-politi...          0.625757  \n",
      "23  https://www.oddschecker.com/politics/us-politi...          0.559891  \n",
      "57  https://www.oddschecker.com/politics/us-politi...          0.551784  \n",
      "1   https://www.oddschecker.com/politics/us-politi...          0.515110  \n",
      "10  https://www.oddschecker.com/politics/us-politi...          0.500567  \n",
      "59  https://www.oddschecker.com/politics/us-politi...          0.453666  \n",
      "77  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "24  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "31  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "20  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "35  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "36  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "68  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "39  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "16  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "4   https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "50  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "82  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "54  https://www.oddschecker.com/politics/us-politi...          0.423756  \n",
      "72  https://www.oddschecker.com/politics/british-p...          0.300571  \n",
      "45  https://www.oddschecker.com/politics/british-p...          0.237283  \n",
      "84  https://www.oddschecker.com/politics/us-politi...          0.171263  \n",
      "73  https://www.oddschecker.com/politics/us-politi...          0.156218  \n",
      "28  https://www.oddschecker.com/politics/us-politi...          0.150789  \n",
      "49  https://www.oddschecker.com/politics/us-politi...          0.113731  \n",
      "29  https://www.oddschecker.com/politics/us-politi...          0.113593  \n",
      "55  https://www.oddschecker.com/politics/us-politi...          0.105788  \n",
      "32  https://www.oddschecker.com/politics/us-politi...          0.105788  \n",
      "22  https://www.oddschecker.com/politics/us-politi...          0.105788  \n",
      "81  https://www.oddschecker.com/politics/us-politi...          0.105788  \n",
      "61  https://www.oddschecker.com/politics/us-politi...          0.073301  \n",
      "53  https://www.oddschecker.com/politics/us-politi...          0.073301  \n",
      "38  https://www.oddschecker.com/politics/us-politi...          0.073301  \n",
      "71  https://www.oddschecker.com/politics/us-politi...          0.073301  \n",
      "74  https://www.oddschecker.com/politics/us-politi...          0.073301  \n",
      "5   https://www.oddschecker.com/politics/us-politi...          0.073301  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Extract market names from Betfair data\n",
    "betfair_market_names = list(set(all_data_df['Market Name'].tolist()))\n",
    "\n",
    "# Combine all market names for vectorization\n",
    "all_market_names = betfair_market_names + urls\n",
    "\n",
    "# Vectorize the market names using TF-IDF\n",
    "vectorizer = TfidfVectorizer().fit_transform(all_market_names)\n",
    "vectors = vectorizer.toarray()\n",
    "\n",
    "# Calculate cosine similarity between Betfair and Oddschecker markets\n",
    "cosine_sim_matrix = cosine_similarity(vectors[:len(betfair_market_names)], vectors[len(betfair_market_names):])\n",
    "\n",
    "# Find the best matches for each Betfair market\n",
    "matches = []\n",
    "for i, betfair_name in enumerate(betfair_market_names):\n",
    "    similarity_scores = cosine_sim_matrix[i]\n",
    "    best_match_idx = np.argmax(similarity_scores)\n",
    "    best_match_score = similarity_scores[best_match_idx]\n",
    "    best_match_name = urls[best_match_idx]\n",
    "    matches.append({\n",
    "        'Betfair Market Name': betfair_name,\n",
    "        'Oddschecker Market Name': best_match_name,\n",
    "        'Similarity Score': best_match_score\n",
    "    })\n",
    "\n",
    "# Convert matches to DataFrame for easier review\n",
    "matches_df = pd.DataFrame(matches)\n",
    "\n",
    "# Filter out rows with a similarity score of 0\n",
    "matches_df_filtered = matches_df[matches_df['Similarity Score'] > 0]\n",
    "\n",
    "# Sort the DataFrame by similarity score in descending order\n",
    "matches_df_filtered = matches_df_filtered.sort_values(by='Similarity Score', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(matches_df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mappings are loaded from data/markets.csv as opposed to the cosine similarity matching above. A fuzzy match is then carried out between the 'Selection Name' from the betfair data and 'Bet' from the oddschecker data as the name of the Bets may not be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Market ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bfair/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Market ID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the mapping CSV file and ensure Market ID is a string for matching consistency\u001b[39;00m\n\u001b[1;32m      5\u001b[0m mapping_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/markets.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m mapping_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmapping_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMarket ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the first DataFrame (Betfair data) and ensure Market ID is a string\u001b[39;00m\n\u001b[1;32m      9\u001b[0m betfair_df \u001b[38;5;241m=\u001b[39m all_data_df\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bfair/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bfair/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Market ID'"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import fuzz\n",
    "from rapidfuzz import process\n",
    "\n",
    "# Load the mapping CSV file and ensure Market ID is a string for matching consistency\n",
    "mapping_df = pd.read_csv(\"../data/markets.csv\")\n",
    "mapping_df['Market ID'] = mapping_df['Market ID'].astype(str)\n",
    "\n",
    "# Load the first DataFrame (Betfair data) and ensure Market ID is a string\n",
    "betfair_df = all_data_df\n",
    "betfair_df['Market ID'] = betfair_df['Market ID'].astype(str)\n",
    "\n",
    "# Load the second DataFrame (Oddschecker data)\n",
    "oddschecker_df = all_data_oc\n",
    "\n",
    "# Normalize the 'Selection Name' and 'Bet' columns for better matching\n",
    "betfair_df['Selection Name Normalized'] = betfair_df['Selection Name'].str.lower().str.strip()\n",
    "oddschecker_df['Bet Normalized'] = oddschecker_df['Bet'].str.lower().str.strip()\n",
    "\n",
    "# Initialize a list to collect all results\n",
    "all_results = []\n",
    "\n",
    "# Iterate over each market in the mapping DataFrame\n",
    "for index, row in mapping_df.iterrows():\n",
    "    market_id = row['Market ID']\n",
    "    url = row['URL']\n",
    "    \n",
    "    # Skip markets without a URL\n",
    "    if pd.isna(url) or url.strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    # Filter Betfair DataFrame to only include rows with the current Market ID\n",
    "    betfair_filtered_df = betfair_df[betfair_df['Market ID'] == market_id]\n",
    "    \n",
    "    # Filter Oddschecker DataFrame to only include rows with the current URL\n",
    "    oddschecker_filtered_df = oddschecker_df[oddschecker_df['URL'] == url]\n",
    "    \n",
    "    # Skip if there are no corresponding entries in either filtered DataFrame\n",
    "    if betfair_filtered_df.empty or oddschecker_filtered_df.empty:\n",
    "        continue\n",
    "    \n",
    "    # Create a function to find the best match for each 'Selection Name'\n",
    "    def match_bets(selection_name, bet_choices):\n",
    "        match, score, _ = process.extractOne(selection_name, bet_choices, scorer=fuzz.token_sort_ratio)\n",
    "        return match, score\n",
    "\n",
    "    # Apply the matching function to each 'Selection Name' in the filtered Betfair DataFrame\n",
    "    bet_choices = oddschecker_filtered_df['Bet Normalized'].tolist()\n",
    "    matches = betfair_filtered_df['Selection Name Normalized'].apply(lambda x: match_bets(x, bet_choices))\n",
    "\n",
    "    # Add match results to betfair_filtered_df\n",
    "    betfair_filtered_df['Best Match Bet'] = matches.apply(lambda x: x[0])\n",
    "    betfair_filtered_df['Similarity Score'] = matches.apply(lambda x: x[1])\n",
    "\n",
    "    # Filter matches based on a similarity threshold (e.g., 80)\n",
    "    threshold = 80\n",
    "    filtered_matches_df = betfair_filtered_df[betfair_filtered_df['Similarity Score'] >= threshold]\n",
    "    \n",
    "    # Merge with the filtered Oddschecker DataFrame on 'URL' and 'Best Match Bet'\n",
    "    final_filtered_df = pd.merge(filtered_matches_df, oddschecker_filtered_df, left_on=['Best Match Bet'], right_on=['Bet'], how='left')\n",
    "    \n",
    "    # Drop temporary columns and finalize DataFrame\n",
    "    final_filtered_df = final_filtered_df.drop(columns=['Selection Name Normalized', 'Bet Normalized', 'Best Match Bet', 'Similarity Score'])\n",
    "    \n",
    "    # Append the results to the all_results list\n",
    "    all_results.append(final_filtered_df)\n",
    "\n",
    "# Concatenate all the DataFrames in the list to create a single DataFrame\n",
    "final_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Display or save the final DataFrame as needed\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mapping CSV file and ensure Market ID is a string for matching consistency\n",
    "mapping_df = pd.read_csv(\"../data/markets.csv\")\n",
    "mapping_df['Market ID'] = mapping_df['Betfair Market ID'].astype(str)\n",
    "\n",
    "# Load the first DataFrame (Betfair data) and ensure Market ID is a string\n",
    "betfair_df = all_data_df\n",
    "betfair_df['Market ID'] = betfair_df['Market ID'].astype(str)\n",
    "\n",
    "# Load the second DataFrame (Oddschecker data)\n",
    "oddschecker_df = all_data_oc\n",
    "\n",
    "# Normalize the 'Selection Name' and 'Bet' columns for better matching\n",
    "betfair_df['Selection Name Normalized'] = betfair_df['Selection Name'].str.lower().str.strip()\n",
    "oddschecker_df['Bet Normalized'] = oddschecker_df['Bet'].str.lower().str.strip()\n",
    "\n",
    "# Initialize a list to collect all results\n",
    "all_results = []\n",
    "\n",
    "# Iterate over each market in the mapping DataFrame\n",
    "for index, row in mapping_df.iterrows():\n",
    "    market_id = row['Market ID']\n",
    "    url = row['Oddschecker URL']\n",
    "    \n",
    "    # Skip markets without a URL\n",
    "    if pd.isna(url) or url.strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    # Filter Betfair DataFrame to only include rows with the current Market ID\n",
    "    betfair_filtered_df = betfair_df[betfair_df['Market ID'] == market_id]\n",
    "    \n",
    "    # Filter Oddschecker DataFrame to only include rows with the current URL\n",
    "    oddschecker_filtered_df = oddschecker_df[oddschecker_df['URL'] == url]\n",
    "    \n",
    "    # Skip if there are no corresponding entries in either filtered DataFrame\n",
    "    if betfair_filtered_df.empty or oddschecker_filtered_df.empty:\n",
    "        continue\n",
    "    \n",
    "    # Perform direct matching of 'Selection Name Normalized' with 'Bet Normalized'\n",
    "    merged_df = pd.merge(\n",
    "        betfair_filtered_df,\n",
    "        oddschecker_filtered_df,\n",
    "        left_on='Selection Name Normalized',\n",
    "        right_on='Bet Normalized',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Drop unnecessary columns from the merged DataFrame\n",
    "    merged_df = merged_df.drop(columns=['Selection Name Normalized', 'Bet Normalized'])\n",
    "    \n",
    "    # Append the results to the all_results list\n",
    "    all_results.append(merged_df)\n",
    "\n",
    "# Concatenate all the DataFrames in the list to create a single DataFrame\n",
    "odds_df = pd.concat(all_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_arbitrage(df):\n",
    "    odds_columns = ['AKB', 'B3', 'BF', 'BY', 'CE', 'DP', 'EE', 'FB', 'FR', 'G5', 'KN', 'LD', 'LS', 'MA', 'N4', 'OE', 'PP', 'QN', 'S6', 'SI', 'SK', 'SX', 'UN', 'VC', 'VT', 'WA', 'WH']\n",
    "    #select_columns = ['Market Name', 'Selection Name', 'Odds to Lay Ratio', 'Best Back Price', 'Best Lay Price', 'Best Lay Size', 'Best Odds', 'Best Bookmaker', 'URL']\n",
    "\n",
    "    # Find the best odds and corresponding bookmaker\n",
    "    df['Best Odds'] = df[odds_columns].max(axis=1)\n",
    "    df['Best Bookmaker'] = df.apply(lambda row: ', '.join([col for col in odds_columns if row[col] == row['Best Odds']]), axis=1)\n",
    "\n",
    "    # Calculate the ratio of Best Odds to Best Lay Price\n",
    "    df['Odds to Lay Ratio'] = df.apply(lambda row: row['Best Odds'] / row['Best Lay Price'] if row['Best Odds'] <= 500 else 0, axis=1)\n",
    "\n",
    "    # Sort the DataFrame by the 'Odds to Lay Ratio' in descending order\n",
    "    df = df.sort_values(by='Odds to Lay Ratio', ascending=False)\n",
    "\n",
    "    # Convert necessary columns to float for calculations\n",
    "    df['Best Odds'] = df['Best Odds'].astype(float)\n",
    "    df['Best Lay Price'] = df['Best Lay Price'].astype(float)\n",
    "    df['Best Lay Size'] = df['Best Lay Size'].astype(float)\n",
    "\n",
    "    # Calculate Lay Liability\n",
    "    df['Lay Liability'] = (df['Best Lay Size'] * (df['Best Lay Price'] - 1)).round(2)\n",
    "\n",
    "    # Calculate Back Amount (B) for hedging\n",
    "    df['Back Amount'] = (df['Best Lay Size'] * df['Best Lay Price'] / (df['Best Odds'])).round(2)\n",
    "\n",
    "    # Calculate Profit\n",
    "    df['Profit If Outcome Happens'] = (df['Back Amount'] * (df['Best Odds'] - 1)) - df['Lay Liability']\n",
    "    df['Profit If Outcome Does Not Happen'] = df['Best Lay Size'] - df['Back Amount']\n",
    "\n",
    "    # Set Profit to the minimum of the two scenarios, rounded to 2 decimal places\n",
    "    df['Profit'] = df[['Profit If Outcome Happens', 'Profit If Outcome Does Not Happen']].min(axis=1).round(2)\n",
    "\n",
    "    # Set Profit to 0 if Best Odds > 500\n",
    "    df.loc[df['Best Odds'] > 500, 'Profit'] = 0\n",
    "\n",
    "    # Filter for potential arbitrage opportunities\n",
    "    arb_opportunities = df[df['Odds to Lay Ratio'] > 1]\n",
    "\n",
    "    # Select and order the columns for the final DataFrame\n",
    "    cols = ['Market Name', 'Selection Name', 'Odds to Lay Ratio', 'Best Odds', 'Best Lay Price', 'Best Lay Size', 'Best Bookmaker',\n",
    "            'Lay Liability', 'Back Amount', 'Profit', 'URL']\n",
    "\n",
    "    return arb_opportunities[cols]\n",
    "\n",
    "arbitrage_opportunities = identify_arbitrage(odds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market Name</th>\n",
       "      <th>Selection Name</th>\n",
       "      <th>Odds to Lay Ratio</th>\n",
       "      <th>Best Odds</th>\n",
       "      <th>Best Lay Price</th>\n",
       "      <th>Best Lay Size</th>\n",
       "      <th>Best Bookmaker</th>\n",
       "      <th>Lay Liability</th>\n",
       "      <th>Back Amount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Next Labour Leader</td>\n",
       "      <td>Darren Jones</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>67.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>10.66</td>\n",
       "      <td>FB, PP</td>\n",
       "      <td>522.34</td>\n",
       "      <td>7.96</td>\n",
       "      <td>2.70</td>\n",
       "      <td>https://www.oddschecker.com/politics/british-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Next Labour Leader</td>\n",
       "      <td>Wes Streeting</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>9.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.01</td>\n",
       "      <td>CE, LD</td>\n",
       "      <td>60.06</td>\n",
       "      <td>7.79</td>\n",
       "      <td>2.22</td>\n",
       "      <td>https://www.oddschecker.com/politics/british-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Democrats</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.60</td>\n",
       "      <td>14.00</td>\n",
       "      <td>DP, KN, LS, UN</td>\n",
       "      <td>36.40</td>\n",
       "      <td>13.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>https://www.oddschecker.com/politics/us-politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Republicans</td>\n",
       "      <td>1.009804</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3157.35</td>\n",
       "      <td>CE, LD</td>\n",
       "      <td>63.15</td>\n",
       "      <td>3126.70</td>\n",
       "      <td>30.65</td>\n",
       "      <td>https://www.oddschecker.com/politics/us-politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Election Winner</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.006061</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1637.94</td>\n",
       "      <td>AKB, S6</td>\n",
       "      <td>1064.66</td>\n",
       "      <td>1628.07</td>\n",
       "      <td>9.87</td>\n",
       "      <td>https://www.oddschecker.com/politics/us-politi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Market Name Selection Name  Odds to Lay Ratio  Best Odds  \\\n",
       "8   Next Labour Leader   Darren Jones           1.340000      67.00   \n",
       "0   Next Labour Leader  Wes Streeting           1.285714       9.00   \n",
       "68             Arizona      Democrats           1.041667       3.75   \n",
       "67         Mississippi    Republicans           1.009804       1.03   \n",
       "56     Election Winner   Donald Trump           1.006061       1.66   \n",
       "\n",
       "    Best Lay Price  Best Lay Size  Best Bookmaker  Lay Liability  Back Amount  \\\n",
       "8            50.00          10.66          FB, PP         522.34         7.96   \n",
       "0             7.00          10.01          CE, LD          60.06         7.79   \n",
       "68            3.60          14.00  DP, KN, LS, UN          36.40        13.44   \n",
       "67            1.02        3157.35          CE, LD          63.15      3126.70   \n",
       "56            1.65        1637.94         AKB, S6        1064.66      1628.07   \n",
       "\n",
       "    Profit                                                URL  \n",
       "8     2.70  https://www.oddschecker.com/politics/british-p...  \n",
       "0     2.22  https://www.oddschecker.com/politics/british-p...  \n",
       "68    0.56  https://www.oddschecker.com/politics/us-politi...  \n",
       "67   30.65  https://www.oddschecker.com/politics/us-politi...  \n",
       "56    9.87  https://www.oddschecker.com/politics/us-politi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(arbitrage_opportunities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Polymarket and Predictit\n",
    "#### Predictit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import json\n",
    "\n",
    "# PredictIt API function\n",
    "async def fetch_predictit_data():\n",
    "    url = \"https://www.predictit.org/api/marketdata/all/\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            data = await response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictit_data = await fetch_predictit_data()\n",
    "\n",
    "predictit_df = pd.json_normalize(predictit_data['markets'])\n",
    "\n",
    "print(predictit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polymarket\n",
    "ClobClient connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_clob_client.client import ClobClient\n",
    "\n",
    "# Polymarket API function\n",
    "host = \"https://clob.polymarket.com\"\n",
    "key = os.getenv(\"PK\")\n",
    "chain_id = 137  # Polygon Mainnet chain ID\n",
    "# Ensure the private key is loaded correctly\n",
    "if not key:\n",
    "    raise ValueError(\"Private key not found. Please set PK in the environment variables.\")\n",
    "# Initialize the client with your private key\n",
    "client = ClobClient(host, key=key, chain_id=chain_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Market data from https://gamma-api.polymarket.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import ast\n",
    "\n",
    "# Fetch data from the Gamma API\n",
    "r = requests.get(\"https://gamma-api.polymarket.com/events?closed=false\")\n",
    "response = r.json()\n",
    "\n",
    "# Function to extract overall market data\n",
    "def extract_overall_market_data(market):\n",
    "    return {\n",
    "        'Market ID': market.get('id', 'N/A'),\n",
    "        'Title': market.get('title', 'N/A'),\n",
    "        'End Date': market.get('endDate', 'N/A'),\n",
    "        'Overall Liquidity': float(market.get('liquidity', 0)),\n",
    "        'Overall Volume': float(market.get('volume', 0)),\n",
    "        'Overall Volume 24hr': float(market.get('volume24hr', 0)),\n",
    "    }\n",
    "\n",
    "# Function to extract individual bet data\n",
    "def extract_bet_data(bet):\n",
    "    outcome_prices_str = bet.get('outcomePrices', '[\"N/A\", \"N/A\"]')\n",
    "    try:\n",
    "        outcome_prices = ast.literal_eval(outcome_prices_str)\n",
    "        yes_price = float(outcome_prices[0]) if len(outcome_prices) > 0 else None\n",
    "        no_price = float(outcome_prices[1]) if len(outcome_prices) > 1 else None\n",
    "    except (ValueError, SyntaxError):\n",
    "        yes_price = None\n",
    "        no_price = None\n",
    "\n",
    "    return {\n",
    "        'Bet ID': bet.get('id'),\n",
    "        'Bet Question': bet.get('question', 'N/A'),\n",
    "        'Bet Liquidity': float(bet.get('liquidity', 0)),\n",
    "        'Bet Volume': float(bet.get('volume', 0)),\n",
    "        'Bet Volume 24hr': float(bet.get('volume24hr', 0)),\n",
    "        'Yes Price': yes_price,\n",
    "        'No Price': no_price,\n",
    "        'CLOB Token ID': bet.get('clobTokenIds')\n",
    "    }\n",
    "\n",
    "# Extract data for all markets and bets\n",
    "market_data = []\n",
    "for market in response:\n",
    "    overall_data = extract_overall_market_data(market)\n",
    "    for bet in market.get('markets', []):\n",
    "        bet_data = extract_bet_data(bet)\n",
    "        combined_data = {**overall_data, **bet_data}\n",
    "        market_data.append(combined_data)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(market_data)\n",
    "\n",
    "# Sort by Overall Volume in descending order\n",
    "df = df.sort_values('Overall Volume', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Display top markets by volume\n",
    "print(\"\\nTop 5 Markets by Volume:\")\n",
    "print(df.nlargest(5, 'Bet Volume')[['Title', 'Bet Question', 'Overall Volume', 'Bet Volume', 'Yes Price', 'No Price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polymarket/Betfair arbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://gamma-api.polymarket.com/events?closed=false\")\n",
    "response = r.json()\n",
    "\n",
    "market_data = []\n",
    "for market in response:\n",
    "    overall_data = extract_overall_market_data(market)\n",
    "    for bet in market.get('markets', []):\n",
    "        bet_data = extract_bet_data(bet)\n",
    "        combined_data = {**overall_data, **bet_data}\n",
    "        market_data.append(combined_data)\n",
    "\n",
    "# Create DataFrame\n",
    "polymarket_df = pd.DataFrame(market_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a price filter for market data\n",
    "price_filter = betfairlightweight.filters.price_projection(\n",
    "    price_data=['EX_BEST_OFFERS']\n",
    ")\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes_list_bf = []\n",
    "\n",
    "# Loop through each market ID and fetch market book data\n",
    "for market_id in market_ids:\n",
    "    # Request market book for each market ID\n",
    "    market_books = client.betting.list_market_book(\n",
    "        market_ids=[market_id],\n",
    "        price_projection=price_filter\n",
    "    )\n",
    "    \n",
    "    # Ensure that market books were returned\n",
    "    if market_books:\n",
    "        # Process the first market book (only one is requested)\n",
    "        market_book = market_books[0]\n",
    "        \n",
    "        # Get market name using the market_id\n",
    "        market_name = market_name_mapping[market_id]\n",
    "        \n",
    "        # Process runner books and store in DataFrame, including selection names and market names\n",
    "        runners_df = process_runner_books(market_book.runners, selection_mapping, market_name, market_id)\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dataframes_list_bf.append(runners_df)\n",
    "\n",
    "# Optionally, you can concatenate all dataframes into a single dataframe\n",
    "betfair_df = pd.concat(dataframes_list_bf, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flexible_selection_mapping(x):\n",
    "    for key, value in selection_mapping.items():\n",
    "        if x.startswith(key):\n",
    "            return value\n",
    "    return x\n",
    "\n",
    "def flexible_market_mapping(x):\n",
    "    for key, value in market_mapping.items():\n",
    "        if x.startswith(key):\n",
    "            return value\n",
    "    return x\n",
    "\n",
    "# Load the mappings from CSV files\n",
    "market_mapping_df = pd.read_csv('../data/market_mapping.csv')\n",
    "selection_mapping_df = pd.read_csv('../data/selection_mapping.csv')\n",
    "\n",
    "# Convert mapping dataframes to dictionaries and ensure all keys and values are strings\n",
    "market_mapping = {str(k): str(v) for k, v in dict(zip(market_mapping_df['polymarket_market_id'], market_mapping_df['betfair_market_id'])).items()}\n",
    "selection_mapping = {str(k): str(v) for k, v in dict(zip(selection_mapping_df['polymarket_bet_id'], selection_mapping_df['betfair_selection_id'])).items()}\n",
    "\n",
    "# Convert IDs to strings in Polymarket dataframe\n",
    "polymarket_df['Market ID'] = polymarket_df['Market ID'].astype(str)\n",
    "polymarket_df['Bet ID'] = polymarket_df['Bet ID'].astype(str)\n",
    "\n",
    "# Apply flexible mappings to Polymarket data\n",
    "polymarket_df['Mapped Market ID'] = polymarket_df['Market ID'].apply(flexible_market_mapping)\n",
    "polymarket_df['Mapped Selection ID'] = polymarket_df['Bet ID'].apply(flexible_selection_mapping)\n",
    "\n",
    "# Rename Betfair columns to match\n",
    "betfair_df = betfair_df.rename(columns={'Market ID': 'Mapped Market ID', 'Selection ID': 'Mapped Selection ID'})\n",
    "\n",
    "# Ensure all relevant columns are strings\n",
    "polymarket_df['Mapped Market ID'] = polymarket_df['Mapped Market ID'].astype(str)\n",
    "polymarket_df['Mapped Selection ID'] = polymarket_df['Mapped Selection ID'].astype(str)\n",
    "betfair_df['Mapped Market ID'] = betfair_df['Mapped Market ID'].astype(str)\n",
    "betfair_df['Mapped Selection ID'] = betfair_df['Mapped Selection ID'].astype(str)\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_df = pd.merge(polymarket_df, betfair_df, \n",
    "                     on=['Mapped Market ID', 'Mapped Selection ID'], \n",
    "                     how='inner', \n",
    "                     suffixes=('_poly', '_bet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_arbitrage(df):\n",
    "    arbitrage_opportunities = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Convert Yes price to decimal odds\n",
    "        yes_odds = 1 / row['Yes Price'] if row['Yes Price'] > 0 else float('inf')\n",
    "        \n",
    "        # Convert No price to decimal odds (as per the screenshot)\n",
    "        no_odds = 1 / (1 - row['No Price']) if row['No Price'] < 1 else float('inf')\n",
    "\n",
    "        # Check arbitrage between Yes price and Betfair Lay price\n",
    "        if row['Best Lay Price'] > yes_odds:\n",
    "            arbitrage_opportunities.append({\n",
    "                'Bet Question': row['Bet Question'],\n",
    "                'Type': 'Yes Price vs Lay Price',\n",
    "                'Yes Odds': yes_odds,\n",
    "                'Lay Price': row['Best Lay Price'],\n",
    "                'Potential Profit %': (row['Best Lay Price'] / yes_odds - 1) * 100\n",
    "            })\n",
    "\n",
    "        # Check arbitrage between No price and Betfair Back price\n",
    "        if row['Best Back Price'] > no_odds:\n",
    "            arbitrage_opportunities.append({\n",
    "                'Bet Question': row['Bet Question'],\n",
    "                'Type': 'No Price vs Back Price',\n",
    "                'No Odds': no_odds,\n",
    "                'Back Price': row['Best Back Price'],\n",
    "                'Potential Profit %': (row['Best Back Price'] / no_odds - 1) * 100\n",
    "            })\n",
    "\n",
    "    return arbitrage_opportunities\n",
    "\n",
    "arbitrage_opps = calculate_arbitrage(merged_df)\n",
    "for opp in arbitrage_opps:\n",
    "     print(opp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polymarket streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import websockets\n",
    "import datetime\n",
    "url = 'wss://ws-subscriptions-clob.polymarket.com/ws/market'\n",
    "last_time_pong = datetime.datetime.now()\n",
    "msgs = []\n",
    "\n",
    "kamala_trump_yes_token = \"69236923620077691027083946871148646972011131466059644796654161903044970987404\"\n",
    "kamala_trump_no_token = \"87584955359245246404952128082451897287778571240979823316620093987046202296181\"\n",
    "\n",
    "trump_win_election_yes = \"21742633143463906290569050155826241533067272736897614950488156847949938836455\"\n",
    "trump_win_election_no = \"48331043336612883890938759509493159234755048973500640148014422747788308965732\"\n",
    "\n",
    "async with websockets.connect(url) as websocket:\n",
    "    await websocket.send(json.dumps({\"assets_ids\":[kamala_trump_yes_token, kamala_trump_no_token],\"type\":\"market\"}))\n",
    "\n",
    "    while True:\n",
    "        m = await websocket.recv()\n",
    "        if m != \"PONG\":\n",
    "          last_time_pong = datetime.datetime.now()\n",
    "        d = json.loads(m)\n",
    "        print(d)\n",
    "        if last_time_pong + datetime.timedelta(seconds=10) < datetime.datetime.now():\n",
    "          await websocket.send(\"PING\")\n",
    "        else:\n",
    "            msgs.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_clob_client.client import ClobClient\n",
    "\n",
    "# Polymarket API function\n",
    "host = \"https://clob.polymarket.com\"\n",
    "pm_key = os.getenv(\"PK\")\n",
    "chain_id = 137  # Polygon Mainnet chain ID\n",
    "# Ensure the private key is loaded correctly\n",
    "if not key:\n",
    "    raise ValueError(\"Private key not found. Please set PK in the environment variables.\")\n",
    "# Initialize the client with your private key\n",
    "pm_client = ClobClient(host, key=pm_key, chain_id=chain_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = pm_client.get_sampling_simplified_markets(next_cursor = \"\",)\n",
    "print(resp)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://gamma-api.polymarket.com/markets?limit=100&closed=false\")\n",
    "response = r.json()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
